{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sentiment analysis of financial data using Hugging Face NLP models\n",
                "\n",
                "This notebook aims to provide an introduction to documenting an NLP model using the ValidMind Developer Framework. The use case presented is a sentiment analysis of financial news data (https://huggingface.co/datasets/financial_phrasebank).\n",
                "\n",
                "- Initializing the ValidMind Developer Framework\n",
                "- Running a test various tests to quickly generate documentation about the data and model\n",
                "\n",
                "## Before you begin\n",
                "\n",
                "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
                "\n",
                "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results.\n",
                "\n",
                "## Install the client library\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -q validmind"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize the client library\n",
                "\n",
                "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
                "\n",
                "::: {.column-margin}\n",
                "::: {.callout-tip}\n",
                "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
                ":::\n",
                ":::\n",
                "\n",
                "Next, replace this placeholder with your own code snippet:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Replace the code below with the code snippet from your project ## \n",
                "\n",
                "import validmind as vm\n",
                "  \n",
                "vm.init(\n",
                "    api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
                "    api_key = \"...\",\n",
                "    api_secret = \"...\",\n",
                "    project = \"...\"\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preview the template\n",
                "\n",
                "A template predefines sections for your documentation project and provides a general outline to follow, making the documentation process much easier.\n",
                "\n",
                "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the vm.preview_template() function from the ValidMind library and note the empty sections:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm.preview_template()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load Dataset\n",
                "\n",
                "In this section, we'll load the financial phrasebank dataset, which will be the foundation for our sentiment analysis tasks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "df = pd.read_csv('./datasets/sentiments.csv')\n",
                "sample = df.sample(10)\n",
                "sample"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## NLP data quality tests\n",
                "\n",
                "Before we proceed with the analysis, it's crucial to ensure the quality of our NLP data. This section runs a data quality test plan to validate the data's integrity and suitability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_ds = vm.init_dataset(\n",
                "    dataset=df,\n",
                "    text_column='Sentence',\n",
                "    target_column=\"Sentiment\"\n",
                ")\n",
                "\n",
                "text_data_test_plan = vm.run_test_plan(\"text_data_quality\", dataset=vm_ds)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Hugging face transformers"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Hugging Face: FinancialBERT-Sentiment-Analysis\n",
                "\n",
                "https://huggingface.co/ahmedrachid/FinancialBERT-Sentiment-Analysis\n",
                "\n",
                "Let's now explore integrating and testing FinancialBERT, a model designed specifically for sentiment analysis in the financial domain."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import BertTokenizer, BertForSequenceClassification\n",
                "from transformers import pipeline\n",
                "\n",
                "model = BertForSequenceClassification.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\",num_labels=3)\n",
                "tokenizer = BertTokenizer.from_pretrained(\"ahmedrachid/FinancialBERT-Sentiment-Analysis\")\n",
                "hfmodel = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize VM dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load a test dataset with 100 rows only\n",
                "vm_test_ds = vm.init_dataset(\n",
                "    dataset=df.head(100),\n",
                "    text_column=\"Sentence\",\n",
                "    target_column=\"Sentiment\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize VM model\n",
                "\n",
                "When initializing a VM model, we pre-calculate predictions on the test dataset. This operation can take a long time for large datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_model_1 = vm.init_model(\n",
                "    hfmodel,\n",
                "    test_ds=vm_test_ds,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run model validation tests\n",
                "\n",
                "It's possible to run a subset of tests on the documentation template by passing a `section` parameter to `run_documentation_tests()`. Let's run the tests that correspond to model validation only."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "full_suite = vm.run_documentation_tests(\n",
                "    section=\"model_development\",\n",
                "    dataset=vm_test_ds,\n",
                "    model=vm_model_1,\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Hugging Face: distilroberta-finetuned-financial-news-sentiment-analysis\n",
                "\n",
                "https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n",
                "\n",
                "The distilroberta model was fine-tuned on the phrasebank dataset: https://huggingface.co/datasets/financial_phrasebank."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
                "hfmodel = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize VM model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_model_2 = vm.init_model(\n",
                "    hfmodel,\n",
                "    test_ds=vm_test_ds,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "full_suite = vm.run_documentation_tests(\n",
                "    section=\"model_development\",\n",
                "    dataset=vm_test_ds,\n",
                "    model=vm_model_2,\n",
                "    models=[vm_model_1]\n",
                "\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Hugging Face: financial-roberta-large-sentiment\n",
                "\n",
                "https://huggingface.co/soleimanian/financial-roberta-large-sentiment\n",
                "\n",
                "The financial-roberta-large model is another financial sentiment analysis model trained on large amounts of data including:\n",
                "\n",
                "- Financial Statements\n",
                "- Earnings Announcements\n",
                "- Earnings Call Transcripts\n",
                "- Corporate Social Responsibility (CSR) Reports\n",
                "- Environmental, Social, and Governance (ESG) News\n",
                "- Financial News\n",
                "- Etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load model directly\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"soleimanian/financial-roberta-large-sentiment\")\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\"soleimanian/financial-roberta-large-sentiment\")\n",
                "hfmodel = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_model_3 = vm.init_model(\n",
                "    hfmodel,\n",
                "    test_ds=vm_test_ds,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "full_suite = vm.run_documentation_tests(\n",
                "    section=\"model_development\",\n",
                "    dataset=vm_test_ds,\n",
                "    model=vm_model_3,\n",
                "    models=[vm_model_1, vm_model_2]\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "dev-framework",
            "language": "python",
            "name": "dev-framework"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
