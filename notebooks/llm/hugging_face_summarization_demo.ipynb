{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization of financial data using Hugging Face LLM models\n",
    "This notebook aims to provide an introduction to documenting an LLM model using the ValidMind Developer Framework. The use case presented is a summarization of financial data (https://huggingface.co/datasets/financial_phrasebank).\n",
    "\n",
    "- Initializing the ValidMind Developer Framework\n",
    "- Running a test various tests to quickly generate document about the data and model\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
    "\n",
    "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results.\n",
    "\n",
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
    "\n",
    "::: {.column-margin}\n",
    "::: {.callout-tip}\n",
    "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
    ":::\n",
    ":::\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anilsorathiya/Library/Caches/pypoetry/virtualenvs/validmind-pPj8dHa5-py3.9/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "2023-09-22 11:29:40,816 - INFO(validmind.api_client): Connected to ValidMind. Project: nlp model sensitivity analysis - Initial Validation (cliop8llc003x32rlklophmdl)\n"
     ]
    }
   ],
   "source": [
    "## Replace the code below with the code snippet from your project ## \n",
    "\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"....\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import textwrap\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "from rouge import Rouge\n",
    "import plotly.graph_objects as go\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import string\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "cnn_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "train_df = cnn_dataset.data['train'].to_pandas()\n",
    "val_df = cnn_dataset.data['validation'].to_pandas()\n",
    "test_df = cnn_dataset.data['test'].to_pandas()\n",
    "train_df = train_df[['article','highlights']]\n",
    "train_df = train_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 11:29:48,106 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "df = train_df.head(100)\n",
    "# Load a test dataset with 100 rows only\n",
    "vm_ds = vm.init_dataset(\n",
    "    dataset=df,\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e65e8d574a94c7c896d35b49007dd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Running test plan...'), IntProgress(value=0, max=14)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anilsorathiya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anilsorathiya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c2b73457ba4b699c501c3b1ce7a795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Results for <i>Text Data Quality</i> Test Plan:</h2><hr>'), HTML(value='<div cl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_data_test_plan = vm.run_test_plan(\"text_data_quality\",\n",
    "                                       dataset=vm_ds,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "@dataclass\n",
    "class AbstractSummarization_HuggingFace:\n",
    "    \"\"\"\n",
    "    A VM Model instance wrapper for abstract summarization using HuggingFace Transformers.\n",
    "    \"\"\"\n",
    "    model: any\n",
    "    tokenizer: any\n",
    "    predicted_prob_values: list = None\n",
    "\n",
    "    def __init__(self, model_name=None, model=None, tokenizer=None):\n",
    "        pipeline_task = \"summarization\"\n",
    "        self.model_name = model_name\n",
    "        self.pipeline_task = pipeline_task\n",
    "        self.model = pipeline(pipeline_task, model=model, tokenizer=tokenizer)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        \"\"\"\n",
    "        Generates summaries for the given texts.\n",
    "        \n",
    "        Parameters:\n",
    "        - texts (list): List of texts to be summarized.\n",
    "        - min_length (int, optional): Minimum length of the produced summary.\n",
    "        - max_length (int, optional): Maximum length of the produced summary.\n",
    "        \n",
    "        Returns:\n",
    "        - List of summaries.\n",
    "        \"\"\"\n",
    "        \n",
    "        # min_length = params.get(\"min_length\")\n",
    "        # max_length = params.get(\"max_length\")\n",
    "        min_length = None\n",
    "        max_length = 50\n",
    "        # If either value is None, don't pass it to the model function\n",
    "        model_args = {}\n",
    "        if min_length is not None:\n",
    "            model_args[\"min_length\"] = min_length\n",
    "        if max_length is not None:\n",
    "            model_args[\"max_length\"] = max_length\n",
    "\n",
    "        summaries = []\n",
    "\n",
    "        for text in texts:\n",
    "            data = [str(text)]\n",
    "            results = self.model(data, **model_args)  # Using ** unpacking to pass arguments conditionally\n",
    "            results_df = pd.DataFrame(results)\n",
    "            summary = results_df[\"summary_text\"].values[0] if \"summary_text\" in results_df.columns else results_df[\"label\"].values[0]\n",
    "            summaries.append(summary)\n",
    "\n",
    "        return summaries\n",
    "\n",
    "\n",
    "    def predict_proba(self):\n",
    "        \"\"\"\n",
    "        Retrieves predicted probabilities after prediction. \n",
    "        Note: Not all models provide predicted probabilities.\n",
    "        \"\"\"\n",
    "        if self.predicted_prob_values is None:\n",
    "            raise ValueError(\"First run predict method to retrieve predicted probabilities\")\n",
    "        return self.predicted_prob_values\n",
    "\n",
    "    def description(self):\n",
    "        \"\"\"\n",
    "        Describes the methods available in the class.\n",
    "\n",
    "        Returns:\n",
    "        - A string describing the methods.\n",
    "        \"\"\"\n",
    "        desc = (\n",
    "            \"This class provides methods for abstract summarization using HuggingFace Transformers.\\n\"\n",
    "            \"1. predict: Generates summaries for given texts. Accepts optional min_length and max_length parameters.\\n\"\n",
    "            \"2. predict_proba: Retrieves predicted probabilities after prediction (if available).\\n\"\n",
    "        )\n",
    "        return desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "summarizer_model = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=model,\n",
    "    tokenizer = tokenizer,\n",
    "    min_length=0,\n",
    "    max_length=60,\n",
    "    truncation=True,\n",
    "    model_kwargs={\"cache_dir\": '/Documents/Huggin_Face/'},\n",
    ")  # Note: We specify cache_dir to use predownloaded models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 11:29:58,940 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "df_test = df.head(100)\n",
    "# Load a test dataset with 100 rows only\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_model = vm.init_model(\n",
    "    summarizer_model,\n",
    "    test_ds=vm_test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_82e59 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82e59_row0_col0, #T_82e59_row0_col1, #T_82e59_row0_col2, #T_82e59_row1_col0, #T_82e59_row1_col1, #T_82e59_row1_col2, #T_82e59_row2_col0, #T_82e59_row2_col1, #T_82e59_row2_col2, #T_82e59_row3_col0, #T_82e59_row3_col1, #T_82e59_row3_col2, #T_82e59_row4_col0, #T_82e59_row4_col1, #T_82e59_row4_col2, #T_82e59_row5_col0, #T_82e59_row5_col1, #T_82e59_row5_col2, #T_82e59_row6_col0, #T_82e59_row6_col1, #T_82e59_row6_col2, #T_82e59_row7_col0, #T_82e59_row7_col1, #T_82e59_row7_col2, #T_82e59_row8_col0, #T_82e59_row8_col1, #T_82e59_row8_col2, #T_82e59_row9_col0, #T_82e59_row9_col1, #T_82e59_row9_col2, #T_82e59_row10_col0, #T_82e59_row10_col1, #T_82e59_row10_col2, #T_82e59_row11_col0, #T_82e59_row11_col1, #T_82e59_row11_col2, #T_82e59_row12_col0, #T_82e59_row12_col1, #T_82e59_row12_col2, #T_82e59_row13_col0, #T_82e59_row13_col1, #T_82e59_row13_col2, #T_82e59_row14_col0, #T_82e59_row14_col1, #T_82e59_row14_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_82e59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_82e59_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_82e59_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_82e59_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row0_col0\" class=\"data row0 col0\" >classifier_metrics</td>\n",
       "      <td id=\"T_82e59_row0_col1\" class=\"data row0 col1\" >ClassifierMetrics</td>\n",
       "      <td id=\"T_82e59_row0_col2\" class=\"data row0 col2\" >Test plan for sklearn classifier metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row1_col0\" class=\"data row1 col0\" >classifier_validation</td>\n",
       "      <td id=\"T_82e59_row1_col1\" class=\"data row1 col1\" >ClassifierPerformance</td>\n",
       "      <td id=\"T_82e59_row1_col2\" class=\"data row1 col2\" >Test plan for sklearn classifier models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row2_col0\" class=\"data row2 col0\" >classifier_model_diagnosis</td>\n",
       "      <td id=\"T_82e59_row2_col1\" class=\"data row2 col1\" >ClassifierDiagnosis</td>\n",
       "      <td id=\"T_82e59_row2_col2\" class=\"data row2 col2\" >Test plan for sklearn classifier model diagnosis tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row3_col0\" class=\"data row3 col0\" >prompt_validation</td>\n",
       "      <td id=\"T_82e59_row3_col1\" class=\"data row3 col1\" >PromptValidation</td>\n",
       "      <td id=\"T_82e59_row3_col2\" class=\"data row3 col2\" >Test plan for prompt validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row4_col0\" class=\"data row4 col0\" >tabular_dataset_description</td>\n",
       "      <td id=\"T_82e59_row4_col1\" class=\"data row4 col1\" >TabularDatasetDescription</td>\n",
       "      <td id=\"T_82e59_row4_col2\" class=\"data row4 col2\" >Test plan to extract metadata and descriptive\n",
       "    statistics from a tabular dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row5_col0\" class=\"data row5 col0\" >tabular_data_quality</td>\n",
       "      <td id=\"T_82e59_row5_col1\" class=\"data row5 col1\" >TabularDataQuality</td>\n",
       "      <td id=\"T_82e59_row5_col2\" class=\"data row5 col2\" >Test plan for data quality on tabular datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row6_col0\" class=\"data row6 col0\" >time_series_data_quality</td>\n",
       "      <td id=\"T_82e59_row6_col1\" class=\"data row6 col1\" >TimeSeriesDataQuality</td>\n",
       "      <td id=\"T_82e59_row6_col2\" class=\"data row6 col2\" >Test plan for data quality on time series datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row7_col0\" class=\"data row7 col0\" >time_series_univariate</td>\n",
       "      <td id=\"T_82e59_row7_col1\" class=\"data row7 col1\" >TimeSeriesUnivariate</td>\n",
       "      <td id=\"T_82e59_row7_col2\" class=\"data row7 col2\" >Test plan to perform time series univariate analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row8_col0\" class=\"data row8 col0\" >time_series_multivariate</td>\n",
       "      <td id=\"T_82e59_row8_col1\" class=\"data row8 col1\" >TimeSeriesMultivariate</td>\n",
       "      <td id=\"T_82e59_row8_col2\" class=\"data row8 col2\" >Test plan to perform time series multivariate analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row9_col0\" class=\"data row9 col0\" >time_series_forecast</td>\n",
       "      <td id=\"T_82e59_row9_col1\" class=\"data row9 col1\" >TimeSeriesForecast</td>\n",
       "      <td id=\"T_82e59_row9_col2\" class=\"data row9 col2\" >Test plan to perform time series forecast tests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row10_col0\" class=\"data row10 col0\" >time_series_sensitivity</td>\n",
       "      <td id=\"T_82e59_row10_col1\" class=\"data row10 col1\" >TimeSeriesSensitivity</td>\n",
       "      <td id=\"T_82e59_row10_col2\" class=\"data row10 col2\" >Test plan to perform time series forecast tests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row11_col0\" class=\"data row11 col0\" >regression_model_description</td>\n",
       "      <td id=\"T_82e59_row11_col1\" class=\"data row11 col1\" >RegressionModelDescription</td>\n",
       "      <td id=\"T_82e59_row11_col2\" class=\"data row11 col2\" >Test plan for performance metric of regression model of statsmodels library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row12_col0\" class=\"data row12 col0\" >regression_models_evaluation</td>\n",
       "      <td id=\"T_82e59_row12_col1\" class=\"data row12 col1\" >RegressionModelsEvaluation</td>\n",
       "      <td id=\"T_82e59_row12_col2\" class=\"data row12 col2\" >Test plan for metrics comparison of regression model of statsmodels library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row13_col0\" class=\"data row13 col0\" >text_data_quality</td>\n",
       "      <td id=\"T_82e59_row13_col1\" class=\"data row13 col1\" >TextDataQuality</td>\n",
       "      <td id=\"T_82e59_row13_col2\" class=\"data row13 col2\" >Test plan for data quality on text data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_82e59_row14_col0\" class=\"data row14 col0\" >summarization_metrics</td>\n",
       "      <td id=\"T_82e59_row14_col1\" class=\"data row14 col1\" >SummarizationMetrics</td>\n",
       "      <td id=\"T_82e59_row14_col2\" class=\"data row14 col2\" >Test plan for Summarization metrics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3cf909940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.list_plans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5d6a9 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d6a9_row0_col0, #T_5d6a9_row0_col1, #T_5d6a9_row0_col2, #T_5d6a9_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d6a9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5d6a9_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_5d6a9_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_5d6a9_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_5d6a9_level0_col3\" class=\"col_heading level0 col3\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5d6a9_row0_col0\" class=\"data row0 col0\" >summarization_metrics</td>\n",
       "      <td id=\"T_5d6a9_row0_col1\" class=\"data row0 col1\" >SummarizationMetrics</td>\n",
       "      <td id=\"T_5d6a9_row0_col2\" class=\"data row0 col2\" >Test plan for Summarization metrics</td>\n",
       "      <td id=\"T_5d6a9_row0_col3\" class=\"data row0 col3\" >RougeMetrics (Metric)<br>TokenDisparity (Metric)<br>BleuScore (Metric)<br>BertScore (Metric)<br>ContextualRecall (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3c76bcdf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"summarization_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae63cee23244607a4132551f4985f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Running test plan...'), IntProgress(value=0, max=10)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fca2e9bc4b42189930f3d74346cf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Results for <i>Summarization Metrics</i> Test Plan:</h2><hr>'), HTML(value='<di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config={\n",
    "    \"rouge_metric\": {\n",
    "        \"rouge_metrics\": [\"rouge-1\",\"rouge-2\", \"rouge-l\"],\n",
    "    },\n",
    "}\n",
    "summarization_metrics = vm.run_test_plan(\"summarization_metrics\", \n",
    "                                             model=vm_model,\n",
    "                                             config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
