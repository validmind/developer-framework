{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Guide to Running Tests with Multiple Datasets\n",
                "\n",
                "This notebook guides you through a mechanism of running a test that requires more than one dataset.\n",
                "\n",
                "This guide includes the code required to:\n",
                "\n",
                "- Load the demo dataset\n",
                "- Prepocess the raw dataset and Train a model for testing\n",
                "- Initialize ValidMind objects\n",
                "- Run a test that requires multiple datasets\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Install the client library\n",
                "\n",
                "The client library provides Python support for the ValidMind Developer Framework. To install it:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6G5-kHOZ7YWk"
            },
            "outputs": [],
            "source": [
                "%pip install -q validmind"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "_ZqI8W5jSPc1"
            },
            "source": [
                "## Initialize the client library\n",
                "\n",
                "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
                "\n",
                "Get your code snippet:\n",
                "\n",
                "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
                "\n",
                "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
                "\n",
                "3. Enter the model details and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/register-models-in-model-inventory.html))\n",
                "\n",
                "   For example, to register a model for use with this notebook, select:\n",
                "\n",
                "   - Documentation template: `Binary classification`\n",
                "   - Use case: `Marketing/Sales - Attrition/Churn Management`\n",
                "\n",
                "   You can fill in other options according to your preference.\n",
                "\n",
                "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
                "\n",
                "Next, replace this placeholder with your own code snippet:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "5hqGn9jHSPc2"
            },
            "outputs": [],
            "source": [
                "# Replace with your code snippet\n",
                "\n",
                "import validmind as vm\n",
                "\n",
                "vm.init(\n",
                "    api_host=\"https://api.prod.validmind.ai/api/v1/tracking\",\n",
                "    api_key=\"...\",\n",
                "    api_secret=\"...\",\n",
                "    project=\"...\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preview the documentation template\n",
                "\n",
                "A template predefines sections for your documentation project and provides a general outline to follow, making the documentation process much easier.\n",
                "\n",
                "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm.preview_template()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "WT4iDaNPSPc4"
            },
            "source": [
                "## Load the sample dataset\n",
                "\n",
                "The sample dataset used here is provided by the ValidMind library. To be able to use it, you need to import the dataset and load it into a pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), a two-dimensional tabular data structure that makes use of rows and columns:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "BlNanClPSPc5"
            },
            "outputs": [],
            "source": [
                "# Import the sample dataset from the library\n",
                "\n",
                "from validmind.datasets.classification import customer_churn as demo_dataset\n",
                "\n",
                "print(\n",
                "    f\"Loaded demo dataset with: \\n\\n\\t• Target column: '{demo_dataset.target_column}' \\n\\t• Class labels: {demo_dataset.class_labels}\"\n",
                ")\n",
                "\n",
                "raw_df = demo_dataset.load_data()\n",
                "raw_df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "XNI6mCy0SPc6"
            },
            "source": [
                "## Prepocess the raw dataset\n",
                "\n",
                "Preprocessing performs a number of operations to get ready for the subsequent steps:\n",
                "\n",
                "- Preprocess the data: Splits the DataFrame (`df`) into multiple datasets (`train_df`, `validation_df`, and `test_df`) using `demo_dataset.preprocess` to simplify preprocessing.\n",
                "- Separate features and targets: Drops the target column to create feature sets (`x_train`, `x_val`) and target sets (`y_train`, `y_val`).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df, validation_df, test_df = demo_dataset.preprocess(raw_df)\n",
                "x_train = train_df.drop(demo_dataset.target_column, axis=1)\n",
                "y_train = train_df[demo_dataset.target_column]\n",
                "x_val = validation_df.drop(demo_dataset.target_column, axis=1)\n",
                "y_val = validation_df[demo_dataset.target_column]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train models for testing\n",
                "\n",
                "Initialize XGBoost and Logistic Regression Classifiers\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "PMeDVcpsSPc7"
            },
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "import xgboost\n",
                "\n",
                "%matplotlib inline\n",
                "\n",
                "xgb = xgboost.XGBClassifier(early_stopping_rounds=10)\n",
                "xgb.set_params(\n",
                "    eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
                ")\n",
                "xgb.fit(\n",
                "    x_train,\n",
                "    y_train,\n",
                "    eval_set=[(x_val, y_val)],\n",
                "    verbose=False,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize ValidMind objects\n",
                "\n",
                "### Initialize the ValidMind model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_model_xgb = vm.init_model(\n",
                "    xgb,\n",
                "    input_id=\"xgb\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "DTO0bN4qSPc7"
            },
            "source": [
                "### Initialize the ValidMind datasets\n",
                "\n",
                "Before you can run tests, you must first initialize a ValidMind dataset object using the [`init_dataset`](https://docs.validmind.ai/validmind/validmind.html#init_dataset) function from the ValidMind (`vm`) module.\n",
                "\n",
                "This function takes a number of arguments:\n",
                "\n",
                "- `dataset` — the raw dataset that you want to provide as input to tests\n",
                "- `input_id` - a unique identifier that allows tracking what inputs are used when running each individual test\n",
                "- `target_column` — a required argument if tests require access to true values. This is the name of the target column in the dataset\n",
                "- `class_labels` — an optional value to map predicted classes to class labels\n",
                "\n",
                "With all datasets ready, you can now initialize the raw, training and test datasets (`raw_df`, `train_df` and `test_df`) created earlier into their own dataset objects using [`vm.init_dataset()`](https://docs.validmind.ai/validmind/validmind.html#init_dataset):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_train_ds = vm.init_dataset(\n",
                "    input_id=\"train_dataset\",\n",
                "    dataset=train_df,\n",
                "    target_column=demo_dataset.target_column,\n",
                ")\n",
                "vm_test_ds = vm.init_dataset(\n",
                "    input_id=\"test_dataset\", dataset=test_df, target_column=demo_dataset.target_column\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run a test that requires multiple datasets\n",
                "\n",
                "We are going to show the following in next two blocks:\n",
                "\n",
                "- Assign predictions for `vm_train_ds` and `vm_test_ds`\n",
                "- Run `RobustnessDiagnosis` which is one example test that takes two input datasets\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run predictions and link with the model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm_train_ds.assign_predictions(model=vm_model_xgb)\n",
                "vm_test_ds.assign_predictions(model=vm_model_xgb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run test\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm.tests.run_test(\n",
                "    \"validmind.model_validation.sklearn.RobustnessDiagnosis\",\n",
                "    inputs={\"datasets\": (vm_train_ds, vm_test_ds), \"model\": vm_model_xgb},\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "gpuClass": "standard",
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
