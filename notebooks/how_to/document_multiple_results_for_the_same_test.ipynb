{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "ZnZV4XfHSPcw"
            },
            "source": [
                "# Rendering more than one unique result for the same metric\n",
                "\n",
                "Documentation templates facilitate the presentation of multiple unique metric results for a single metric. Consider various scenarios where you may intend to showcase results of the same metric with diverse inputs:\n",
                "\n",
                "**Comparing test results with varied parameter values:** Illustrate metric performance by contrasting test results achieved with different parameter values to identify optimal settings.\n",
                "\n",
                "**Displaying test results with distinct datasets:** Showcase metric versatility by presenting results on diverse datasets, such as providing confusion matrices for both training and test data.\n",
                "\n",
                "**Model comparison:** Conduct a comprehensive model evaluation by comparing metrics like `ROC curve` and `Accuracy` to discern and select the superior-performing model.\n",
                "\n",
                "This interactive notebook guides you through the process of documenting a model with the ValidMind Developer Framework. It uses the [Bank Customer Churn Prediction](https://www.kaggle.com/code/kmalit/bank-customer-churn-prediction/data) sample dataset from Kaggle to train a simple classification model.\n",
                "\n",
                "As part of the notebook, you will learn how to render more than one unique metric result for the same metric while exploring how the documentation process works:\n",
                "\n",
                "- Initializing the ValidMind Developer Framework\n",
                "- Loading a sample dataset provided by the library to train a simple classification model\n",
                "- Running a ValidMind test suite to quickly generate documentation about the data and model"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ValidMind at a glance\n",
                "\n",
                "ValidMind's platform enables organizations to identify, document, and manage model risks for all types of models, including AI/ML models, LLMs, and statistical models. As a model developer, you use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on documentation projects. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
                "\n",
                "If this is your first time trying out ValidMind, you can make use of the following resources alongside this notebook:\n",
                "\n",
                "- [Get started](https://docs.validmind.ai/guide/get-started.html) — The basics, including key concepts, and how our products work\n",
                "- [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/guide/get-started-developer-framework.html) —  The path for developers, more code samples, and our developer reference"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "ZNcbDRubSPc1"
            },
            "source": [
                "## Before you begin\n",
                "\n",
                "::: {.callout-tip}\n",
                "### New to ValidMind? \n",
                "For access to all features available in this notebook, create a free ValidMind account. \n",
                "\n",
                "Signing up is FREE — [**Sign up now**](https://app.prod.validmind.ai)\n",
                ":::\n",
                "\n",
                "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html)."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Install the client library\n",
                "\n",
                "The client library provides Python support for the ValidMind Developer Framework. To install it:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "6G5-kHOZ7YWk"
            },
            "outputs": [],
            "source": [
                "%pip install -q validmind"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "_ZqI8W5jSPc1"
            },
            "source": [
                "## Initialize the client library\n",
                "\n",
                "Every documentation project in the Platform UI comes with a _code snippet_ that lets the client library associate your documentation and tests with the right project on the Platform UI when you run this notebook. As you will see later, documentation projects are useful because they act as containers for model documentation and validation reports and they enable you to organize all of your documentation work in one place. \n",
                "\n",
                "Get your code snippet by creating a documentation project:\n",
                "\n",
                "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
                "\n",
                "2. Go to **Documentation Projects** and click **Create new project**.\n",
                "\n",
                "3. Select **`[Demo] Customer Churn Model`** and **`Initial Validation`** for the model name and type, give the project a unique  name to make it yours, and then click **Create project**.\n",
                "\n",
                "4. Go to **Documentation Projects** > **YOUR_UNIQUE_PROJECT_NAME** > **Getting Started** and click **Copy snippet to clipboard**.\n",
                "\n",
                "Next, replace this placeholder with your own code snippet:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "5hqGn9jHSPc2"
            },
            "outputs": [],
            "source": [
                "## Replace this placeholder with the code snippet from your own project ##\n",
                "\n",
                "\n",
                "import validmind as vm\n",
                "\n",
                "vm.init(\n",
                "  api_host = \"...\",\n",
                "  api_key = \"...\",\n",
                "  api_secret = \"...\",\n",
                "  project = \"...\"\n",
                ")\n",
                "  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Update the customer churn demo template\n",
                "\n",
                "Before you initialize the client library by running the notebook, edit the **Binary classification** template to make a copy of a metric of interest and update it with different `result_id` fields for each entry:\n",
                "\n",
                "- Go to **Settings > Templates** and click on the **Binary classification** template. Let's say we want to show `Skewness` results for `training` and `test` datasets.\n",
                "\n",
                "To do this we replace\n",
                "\n",
                "```yaml\n",
                "- content_type: test\n",
                "  content_id: validmind.data_validation.Skewness\n",
                "```\n",
                "\n",
                "with\n",
                "\n",
                "```yaml\n",
                "- content_type: test\n",
                "  content_id: validmind.data_validation.Skewness:training_data\n",
                "- content_type: test\n",
                "  content_id: validmind.data_validation.Skewness:test_data\n",
                "```\n",
                "\n",
                "This way, we can show two results of the same test in the model document. Here, the `training_data` and `test_data` could be any string. However, they should be unique for the same test.\n",
                "\n",
                "- Click on **Prepare new version**, provide some version notes and click on **Save new version** to save a new version of this template.\n",
                "- Next, we need to swap our project to use this new version of the template. Follow the steps on this guide to swap the template of our customer churn model: https://docs.validmind.ai/guide/swap-documentation-project-templates.html.\n",
                "\n",
                "In the following sections we provide more context on how these `content_id` fields mentioned earlier get mapped to the actual tests."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize the Python environment\n",
                "\n",
                "Next, let's import the necessary libraries and set up your Python environment for data analysis:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import xgboost as xgb\n",
                "\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preview the documentation template\n",
                "\n",
                "A template predefines sections for your documentation project and provides a general outline to follow, making the documentation process much easier.\n",
                "\n",
                "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections. You will see two blocks with different result IDs for skewness."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vm.preview_template()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "WT4iDaNPSPc4"
            },
            "source": [
                "## Load the sample dataset\n",
                "\n",
                "The sample dataset used here is provided by the ValidMind library, along with a second, different dataset (`taiwan_credit`) you can try as well. \n",
                "\n",
                "To be able to use either sample dataset, you need to import the dataset and load it into a pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), a two-dimensional tabular data structure that makes use of rows and columns:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "BlNanClPSPc5"
            },
            "outputs": [],
            "source": [
                "# Import the sample dataset from the library\n",
                "\n",
                "from validmind.datasets.classification import customer_churn as demo_dataset\n",
                "\n",
                "df = demo_dataset.load_data()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "7iMY_9V3SPc5"
            },
            "source": [
                "### Initialize a ValidMind dataset object\n",
                "\n",
                "Before you can run a test suite, which are a collection of tests, you must first initialize a ValidMind dataset object using the [`init_dataset`](https://docs.validmind.ai/validmind/validmind.html#init_dataset) function from the ValidMind (`vm`) module. \n",
                "\n",
                "This function takes a number of arguments: \n",
                "\n",
                "- `dataset` — the raw dataset that you want to analyze\n",
                "- `target_column` — the name of the target column in the dataset \n",
                "- `class_labels` — the list of class labels used for classification model training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "X64u5AbHSPc6"
            },
            "outputs": [],
            "source": [
                "vm_dataset = vm.init_dataset(\n",
                "    input_id=\"raw_dataset\",\n",
                "    dataset=df,\n",
                "    target_column=demo_dataset.target_column,\n",
                "    class_labels=demo_dataset.class_labels\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "sP6OZpdGSPc6"
            },
            "source": [
                "## Document the model\n",
                "\n",
                "As part of documenting the model with the ValidMind Developer Framework, you need to preprocess the raw dataset, initialize some training and test datasets, initialize a model object you can use for testing, and then run the full suite of tests. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "XNI6mCy0SPc6"
            },
            "source": [
                "### Prepare datasets\n",
                "\n",
                "DataFrame (df) preprocessing is simplified by employing `demo_dataset.preprocess` to partition it into distinct datasets (`train_df`, `validation_df`, and `test_df`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "PMeDVcpsSPc7"
            },
            "outputs": [],
            "source": [
                "train_df, validation_df, test_df = demo_dataset.preprocess(df)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "id": "DTO0bN4qSPc7"
            },
            "source": [
                "### Initialize the training and test datasets\n",
                "\n",
                "With the datasets ready, you can now initialize the training and test datasets (`train_df` and `test_df`) created earlier into their own dataset objects using [`vm.init_dataset()`](https://docs.validmind.ai/validmind/validmind.html#init_dataset):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "ShiOFS7bSPc7"
            },
            "outputs": [],
            "source": [
                "vm_train_ds = vm.init_dataset(\n",
                "    input_id=\"train_dataset\",\n",
                "    dataset=train_df,\n",
                "    target_column=demo_dataset.target_column\n",
                ")\n",
                "\n",
                "vm_test_ds = vm.init_dataset(\n",
                "    input_id=\"test_dataset\",\n",
                "    dataset=test_df,\n",
                "    target_column=demo_dataset.target_column\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run documentation tests \n",
                "Now specify `inputs` and `params` for individual tests using `config` parameter. The results for the both the datasets will be visible in the documentation. The `inputs` in the config get priority over global `inputs` in the `run_documentation_tests`. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "        \"validmind.data_validation.Skewness:training_data\": {\n",
                "            \"params\": { \"max_threshold\": 1 },\n",
                "            \"inputs\": { \"dataset\": vm_train_ds }\n",
                "        },\n",
                "        \"validmind.data_validation.Skewness:test_data\": {\n",
                "            \"params\": { \"max_threshold\": 1.5 },\n",
                "            \"inputs\": { \"dataset\": vm_test_ds }\n",
                "        },\n",
                "}\n",
                "\n",
                "tests_suite = vm.run_documentation_tests(\n",
                "    inputs = {\n",
                "        \"dataset\":vm_dataset,\n",
                "    },\n",
                "    config = config,\n",
                "    section=[\"data_preparation\"]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run the individual tests using  the `run_test`\n",
                "Now run the `Skewness` tests for training and test datasets. The results for the both the datasets will be visible in the documentation. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test = vm.tests.run_test(\n",
                "    test_id=\"validmind.data_validation.Skewness:training_data\",\n",
                "    params={\n",
                "        \"max_threshold\": 1\n",
                "    },\n",
                "    inputs = {\n",
                "        \"dataset\":vm_train_ds\n",
                "    }\n",
                ")\n",
                "test.log()\n",
                "\n",
                "test = vm.tests.run_test(\n",
                "    test_id=\"validmind.data_validation.Skewness:test_data\",\n",
                "    params={\n",
                "        \"max_threshold\": 1.5\n",
                "    },\n",
                "    inputs = {\n",
                "        \"dataset\":vm_test_ds,\n",
                "    }\n",
                ")\n",
                "test.log()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next steps\n",
                "\n",
                "You can look at the results of this test suite right in the notebook where you ran the code, as you would expect. But there is a better way: view the test results as part of your model documentation right in the ValidMind Platform UI: \n",
                "\n",
                "1. Log back into the [Platform UI](https://app.prod.validmind.ai) \n",
                "\n",
                "2. Go to **Documentation Projects** > **YOUR_UNIQUE_PROJECT_NAME** > **Documentation**.\n",
                "\n",
                "3. Expand the following sections and take a look around:\n",
                "   \n",
                "   - **2. Data Preparation**\n",
                "   \n",
                "   You can now see the skewness tests results of training and test datasets in the `Data Preparation` section. \n",
                "\n",
                "If you want to learn more about where you are in the model documentation process, take a look at [How do I use the framework?](https://docs.validmind.ai/guide/get-started-developer-framework.html#how-do-i-use-the-framework).\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "gpuClass": "standard",
        "kernelspec": {
            "display_name": "validmind-1QuffXMV-py3.9",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
