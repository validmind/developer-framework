{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Default Model using ValidMind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: Connect Notebook to ValidMind Project\n",
    "- Step 2: Import Raw Data\n",
    "- Step 3: Data Description on Raw Data\n",
    "- Step 4: Data Preprocessing\n",
    "- Step 5: Data Description on Preprocessed Data \n",
    "- Step 6: Univariate Analysis\n",
    "- Step 7: Multivariate Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Connect Notebook to ValidMind Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key and secret from environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv .env\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect Notebook to ValidMind Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"cliwzqjgv00001fy6869rlav9\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import list_tests, load_test, describe_test\n",
    "\n",
    "list_tests(filter=\"data_validation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Raw Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Lending Club Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the zip file\n",
    "# filepath = '/Users/juanvalidmind/Dev/datasets/lending club/data_2007_2014/loan_data_2007_2014.csv'\n",
    "filepath = '/Users/juanvalidmind/Dev/datasets/lending club/data_2007_2011/lending_club_loan_data_2007_2011.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# ONLY FOR TESTING\n",
    "\n",
    "\n",
    "# Perform operations on the DataFrame as needed\n",
    "print(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Description on Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.vm_models.test_context import TestContext\n",
    "from validmind.data_validation.metrics import TabularDescriptionTables\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df)\n",
    "test_context = TestContext(dataset=vm_df)\n",
    "metric = TabularDescriptionTables(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Unused Variables\n",
    "\n",
    "Remove all the **Demographic** and **Customer Behavioural** features which is of no use for default analysis for credit approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-required columns\n",
    "# id - not required\n",
    "# member_id - not required\n",
    "# acc_now_delinq - empty\n",
    "# funded_amnt - not useful, funded_amnt_inv is useful which is funded to person\n",
    "# emp_title - brand names not useful\n",
    "# pymnt_plan - fixed value as n for all\n",
    "# url - not useful\n",
    "# desc - can be applied some NLP but not for EDA\n",
    "# title - too many distinct values not useful\n",
    "# zip_code - complete zip is not available\n",
    "# delinq_2yrs - post approval feature\n",
    "# mths_since_last_delinq - only half values are there, not much information\n",
    "# mths_since_last_record - only 10% values are there\n",
    "# revol_bal - post/behavioural feature\n",
    "# initial_list_status - fixed value as f for all\n",
    "# out_prncp - post approval feature\n",
    "# out_prncp_inv - not useful as its for investors\n",
    "# total_pymnt - post approval feature\n",
    "# total_pymnt_inv - not useful as it is for investors\n",
    "# total_rec_prncp - post approval feature\n",
    "# total_rec_int - post approval feature\n",
    "# total_rec_late_fee - post approval feature\n",
    "# recoveries - post approval feature\n",
    "# collection_recovery_fee - post approval feature\n",
    "# last_pymnt_d - post approval feature\n",
    "# last_credit_pull_d - irrelevant for approval\n",
    "# last_pymnt_amnt - post feature\n",
    "# next_pymnt_d - post feature\n",
    "# collections_12_mths_ex_med - only 1 value \n",
    "# policy_code - only 1 value\n",
    "# acc_now_delinq - single valued\n",
    "# application_type - single\n",
    "# pub_rec_bankruptcies - single valued for more than 99%\n",
    "# addr_state - may not depend on location as its in financial domain\n",
    "\n",
    "unused_variables = [\"id\", \"member_id\", \"funded_amnt\", \"emp_title\", \"pymnt_plan\", \"url\", \"desc\",\n",
    "                    \"title\", \"zip_code\", \"delinq_2yrs\", \"mths_since_last_delinq\", \"mths_since_last_record\",\n",
    "                    \"revol_bal\", \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n",
    "                    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\", \"recoveries\",\n",
    "                    \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\", \"next_pymnt_d\", \"last_credit_pull_d\",\n",
    "                    \"collections_12_mths_ex_med\", \"policy_code\", \"acc_now_delinq\", \"application_type\", \"addr_state\"]\n",
    "df_selected_vars = df.drop(columns=unused_variables)\n",
    "print(\"Features we are left with\",list(df_selected_vars.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_vars.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process `emp_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emp_length(df, column='emp_length'):\n",
    "    # Define a mapping from original string values to numeric values\n",
    "    mapping = {'10+ years': 10, '< 1 year': 0, '1 year': 1, '2 years': 2, \n",
    "               '3 years': 3, '4 years': 4, '5 years': 5, '6 years': 6, \n",
    "               '7 years': 7, '8 years': 8, '9 years': 9, np.nan: np.nan}\n",
    "    \n",
    "    # Apply the mapping to the specified column\n",
    "    df[column] = df[column].map(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_vars = process_emp_length(df_selected_vars, 'emp_length')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df, columns):\n",
    "    # Specify the date format\n",
    "    date_format = \"%b-%y\"\n",
    "\n",
    "    # Iterate over the specified columns and convert to datetime\n",
    "    for column in columns:\n",
    "        df[column] = pd.to_datetime(df[column], format=date_format)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the specified columns to datetime\n",
    "columns_to_convert = ['issue_d']\n",
    "df_dates_fixed = convert_to_datetime(df_selected_vars, columns_to_convert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Variables with Large Number of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_with_min_missing(df, min_missing_percentage):\n",
    "    # Calculate the percentage of missing values in each column\n",
    "    missing_percentages = df.isnull().mean() * 100\n",
    "\n",
    "    # Get the variables where the percentage of missing values is greater than the specified minimum\n",
    "    variables_to_drop = missing_percentages[missing_percentages > min_missing_percentage].index.tolist()\n",
    "\n",
    "    return variables_to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_missing_count = 80\n",
    "variables_to_drop = variables_with_min_missing(df_dates_fixed, min_missing_count)\n",
    "df_no_missing = df_dates_fixed.drop(columns=variables_to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing.dropna(axis=0, subset=[\"emp_length\"], inplace=True)\n",
    "df_no_missing.dropna(axis=0, subset=[\"revol_util\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Rows with Loan Status `Current` \n",
    "\n",
    "Removing records with loan status as **`Current`**, as the loan is currently running and we can’t infer any information regarding default from such loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with loan_status as \"Current\"\n",
    "df_no_current = df_no_missing[df_no_missing[\"loan_status\"].apply(lambda x: False if x == \"Current\" else True)]\n",
    "\n",
    "# Update loan_status as Fully Paid to 0 and Charged Off to 1\n",
    "df_no_current[\"loan_status\"] = df_no_current[\"loan_status\"].apply(lambda x: 0 if x == \"Fully Paid\" else 1)\n",
    "\n",
    "# Convert 'emp_length' to string type\n",
    "df_no_current[\"emp_length\"] = df_no_current[\"emp_length\"].astype(str)\n",
    "\n",
    "# Update emp_length feature with continuous values as int\n",
    "# where (< 1 year) is assumed as 0 and 10+ years is assumed as 10 and rest are stored as their magnitude\n",
    "df_no_current[\"emp_length\"] = pd.to_numeric(df_no_current[\"emp_length\"].apply(lambda x: 0 if \"<\" in x else (x.split('+')[0] if \"+\" in x else x.split()[0])))\n",
    "\n",
    "# Look through the purpose value counts\n",
    "loan_purpose_values = df_no_current[\"purpose\"].value_counts() * 100 / df_no_current.shape[0]\n",
    "\n",
    "# Remove rows with less than 1% of value counts in particular purpose \n",
    "loan_purpose_delete = loan_purpose_values[loan_purpose_values < 1].index.values\n",
    "df_processed = df_no_current[[False if p in loan_purpose_delete else True for p in df_no_current[\"purpose\"]]]\n",
    "\n",
    "# Update int_rate, revol_util without % sign and as numeric type\n",
    "df_processed[\"int_rate\"] = pd.to_numeric(df_processed[\"int_rate\"].apply(lambda x:x.split('%')[0]))\n",
    "df_processed[\"revol_util\"] = pd.to_numeric(df_processed[\"revol_util\"].apply(lambda x:x.split('%')[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting month and year from issue_date\n",
    "df_processed['month'] = df_processed['issue_d'].apply(lambda x: x.month)\n",
    "df_processed['year'] = df_processed['issue_d'].apply(lambda x: x.year)\n",
    "\n",
    "# Get year from issue_d and replace the same\n",
    "df_processed[\"earliest_cr_line\"] = pd.to_numeric(df_processed[\"earliest_cr_line\"].apply(lambda x:x.split('-')[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning Continuous Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bins for `loan_amnt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for loan_amnt range\n",
    "bins = [0, 5000, 10000, 15000, 20000, 25000, 36000]\n",
    "bucket_l = ['0-5000', '5000-10000', '10000-15000', '15000-20000', '20000-25000','25000+']\n",
    "df_processed['loan_amnt_range'] = pd.cut(df_processed['loan_amnt'], bins, labels=bucket_l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bins for `int_rate` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'int_rate' to numeric\n",
    "df_processed['int_rate'] = pd.to_numeric(df_processed['int_rate'], errors='coerce')\n",
    "\n",
    "# Create bins for int_rate range\n",
    "bins = [0, 7.5, 10, 12.5, 15, 100]\n",
    "bucket_l = ['0-7.5', '7.5-10', '10-12.5', '12.5-15', '15+']\n",
    "\n",
    "# Using pd.cut to create 'int_rate_range' column\n",
    "df_processed['int_rate_range'] = pd.cut(df_processed['int_rate'], bins, labels=bucket_l)\n",
    "\n",
    "# Convert NaN to 'Unknown'\n",
    "df_processed['int_rate_range'] = df_processed['int_rate_range'].cat.add_categories('Unknown')\n",
    "df_processed['int_rate_range'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bins for `annual_inc` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for annual_inc range\n",
    "bins = [0, 25000, 50000, 75000, 100000, 1000000]\n",
    "bucket_l = ['0-25000', '25000-50000', '50000-75000', '75000-100000', '100000+']\n",
    "df_processed['annual_inc_range'] = pd.cut(df_processed['annual_inc'], bins, labels=bucket_l)\n",
    "\n",
    "# Convert NaN to 'Unknown'\n",
    "df_processed['annual_inc_range'] = df_processed['annual_inc_range'].cat.add_categories('Unknown')\n",
    "df_processed['annual_inc_range'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bins for `installment` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for installment range\n",
    "def installment(n):\n",
    "    if n <= 200:\n",
    "        return 'low'\n",
    "    elif n > 200 and n <=500:\n",
    "        return 'medium'\n",
    "    elif n > 500 and n <=800:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'very high'\n",
    "\n",
    "df_processed['installment'] = df_processed['installment'].apply(lambda x: installment(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bins for `dti` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for dti range\n",
    "bins = [-1, 5.00, 10.00, 15.00, 20.00, 25.00, 50.00]\n",
    "bucket_l = ['0-5%', '5-10%', '10-15%', '15-20%', '20-25%', '25%+']\n",
    "df_processed['dti_range'] = pd.cut(df_processed['dti'], bins, labels=bucket_l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Description on Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_df = vm.init_dataset(dataset=df_processed,\n",
    "                        target_column='loan_status')\n",
    "test_context = TestContext(dataset=vm_df)\n",
    "metric = TabularDescriptionTables(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Univariate Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for amount of defaults in the data using countplot\n",
    "plt.figure()\n",
    "sns.countplot(y=\"loan_status\", data=df_processed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.data_validation.ClassImbalance import ClassImbalance\n",
    "metric = ClassImbalance(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.data_validation.MissingValues import MissingValues\n",
    "metric = MissingValues(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.data_validation.metrics import TabularNumericalHistograms\n",
    "metric = TabularNumericalHistograms(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.data_validation.HighCardinality import HighCardinality\n",
    "metric = HighCardinality(test_context)\n",
    "metric.run()\n",
    "metric.result.show()\n",
    "\n",
    "HighCardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.data_validation.metrics import TabularCategoricalBarPlots\n",
    "metric = TabularCategoricalBarPlots(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.data_validation.metrics import TabularDateTimeHistograms\n",
    "metric = TabularDateTimeHistograms(test_context)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Defaults Ratio by Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.data_validation.metrics import LoanDefaultRatio\n",
    "\n",
    "# Select numerical and categorical features \n",
    "numerical_features = ['emp_length', 'month', 'year', 'earliest_cr_line', 'inq_last_6mths', 'revol_util', 'total_acc',\n",
    "                       'loan_amnt_range', 'int_rate_range', 'dti_range', 'installment', 'annual_inc_range']\n",
    "categorical_features = ['term', 'grade', 'sub_grade', 'home_ownership', 'verification_status', 'purpose', 'open_acc', 'pub_rec']\n",
    "\n",
    "# Configure the metric\n",
    "params = {\n",
    "    \"loan_status_col\": \"loan_status\",\n",
    "    \"columns\": numerical_features + categorical_features\n",
    "}\n",
    "\n",
    "test_context = TestContext(dataset=vm_df)\n",
    "metric = LoanDefaultRatio(test_context, params=params)\n",
    "metric.run()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Multivariate Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select variables for multivariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = ['loan_status']\n",
    "selected_features = ['term', 'grade', 'purpose', 'pub_rec',\n",
    "                      'revol_util', 'funded_amnt_inv', 'int_rate', \n",
    "                      'annual_inc_range', 'dti', 'installment',\n",
    "                      'loan_amnt_range', 'annual_inc', 'loan_amnt',\n",
    "                      'earliest_cr_line']\n",
    "df_multivariate = df_processed.loc[:, selected_features + target_variable]\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df_multivariate)\n",
    "test_context = TestContext(dataset=vm_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define metric as custom test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from validmind.vm_models import Figure, Metric\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BivariateBarPlots(Metric):\n",
    "    \"\"\"\n",
    "    Generates a visual analysis of categorical data by plotting bivariate bar plots.\n",
    "    The input dataset and variable_pairs are required.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"bivariate_bar_plots\"\n",
    "    required_context = [\"dataset\"]\n",
    "    default_params = {\"variable_pairs\": None, \"loan_status_filter\": None}\n",
    "\n",
    "    def plot_bivariate_bar(self, variable_pairs, loan_status_filter):\n",
    "        figures = []\n",
    "        for x, hue in variable_pairs.items():\n",
    "            df = self.dataset.df\n",
    "            if loan_status_filter:\n",
    "                df = df[df[\"loan_status\"].isin(loan_status_filter)]\n",
    "\n",
    "            means = df.groupby([x, hue])[\"loan_status\"].mean().unstack().reset_index()\n",
    "            hue_categories = means.columns[1:]\n",
    "\n",
    "            n = len(hue_categories)\n",
    "            width = 1 / (n + 1)\n",
    "\n",
    "            plt.figure()\n",
    "\n",
    "            color_palette = {\n",
    "                category: color\n",
    "                for category, color in zip(\n",
    "                    hue_categories, plt.cm.get_cmap(\"tab10\").colors\n",
    "                )\n",
    "            }\n",
    "\n",
    "            for i, hue_category in enumerate(hue_categories):\n",
    "                plt.bar(\n",
    "                    np.arange(len(means)) + i * width,\n",
    "                    means[hue_category],\n",
    "                    color=color_palette[hue_category],\n",
    "                    alpha=0.7,\n",
    "                    label=hue_category,\n",
    "                    width=width,\n",
    "                )\n",
    "\n",
    "            plt.title(x + \" by \" + hue)\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(\"Loan Default Ratio\")\n",
    "            plt.xticks(ticks=np.arange(len(means)), labels=means[x], rotation=90)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            figures.append(\n",
    "                Figure(\n",
    "                    for_object=self, key=f\"{self.key}:{x}_{hue}\", figure=plt.figure()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        return figures\n",
    "\n",
    "    def run(self):\n",
    "        variable_pairs = self.params[\"variable_pairs\"]\n",
    "        loan_status_filter = self.params[\"loan_status_filter\"]\n",
    "\n",
    "        figures = self.plot_bivariate_bar(variable_pairs, loan_status_filter)\n",
    "\n",
    "        return self.cache_results(figures=figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: this does not work - from validmind.tests.data_validation.BivariateBarPlots import BivariateBarPlots\n",
    "\n",
    "# Configure the metric\n",
    "variable_pairs = {'annual_inc_range': 'purpose', \n",
    "                  'term': 'purpose', \n",
    "                  'grade': 'purpose',\n",
    "                  'loan_amnt_range': 'purpose',\n",
    "                  'loan_amnt_range': 'term',\n",
    "                  'installment': 'purpose'}\n",
    "\n",
    "params = {\n",
    "    \"variable_pairs\": variable_pairs,\n",
    "    \"loan_status_filter\": None\n",
    "}\n",
    "\n",
    "metric = BivariateBarPlots(test_context, params=params)\n",
    "#metric.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multivariate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from validmind.vm_models import Figure, Metric\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BivariateScatterPlots(Metric):\n",
    "    \"\"\"\n",
    "    Generates a visual analysis of categorical data by plotting bivariate scatter plots.\n",
    "    The input dataset and variable_pairs are required.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"bivariate_scatter_plots\"\n",
    "    required_context = [\"dataset\"]\n",
    "    default_params = {\"variable_pairs\": None, \"loan_status_filter\": None}\n",
    "\n",
    "    def plot_bivariate_scatter(self, variable_pairs, loan_status_filter):\n",
    "        figures = []\n",
    "        for x, y in variable_pairs.items():\n",
    "            df = self.dataset.df\n",
    "            if loan_status_filter:\n",
    "                df = df[df[\"loan_status\"] == loan_status_filter]\n",
    "\n",
    "            plt.figure()\n",
    "\n",
    "            # Scatterplot using seaborn, with color variation based on 'loan_status'\n",
    "            # Create color mapping with rgba values, last value is alpha (transparency)\n",
    "            palette = {0: (0.8, 0.8, 0.8, 0.8), 1: 'tab:red'}\n",
    "            plot = sns.scatterplot(data=df, x=x, y=y, hue='loan_status', palette=palette, alpha=1)\n",
    "\n",
    "            # Change legend labels\n",
    "            legend_labels = ['Default' if t.get_text()=='1' else 'Non-default' for t in plot.legend_.texts[1:]]\n",
    "            plot.legend_.texts[1:] = legend_labels\n",
    "\n",
    "            plt.title(x + \" and \" + y)\n",
    "            plt.xlabel(x)\n",
    "            plt.ylabel(y)\n",
    "            plt.show()\n",
    "\n",
    "            figures.append(\n",
    "                Figure(\n",
    "                    for_object=self, key=f\"{self.key}:{x}_{y}\", figure=plt.figure()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        return figures\n",
    "\n",
    "    def run(self):\n",
    "        variable_pairs = self.params[\"variable_pairs\"]\n",
    "        loan_status_filter = self.params[\"loan_status_filter\"]\n",
    "\n",
    "        figures = self.plot_bivariate_scatter(variable_pairs, loan_status_filter)\n",
    "\n",
    "        return self.cache_results(figures=figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_pairs = {'int_rate': 'annual_inc', \n",
    "                  'funded_amnt_inv': 'dti', \n",
    "                  'annual_inc': 'funded_amnt_inv',\n",
    "                  'loan_amnt': 'int_rate',\n",
    "                  'int_rate': 'annual_inc',\n",
    "                  'earliest_cr_line': 'int_rate'}\n",
    "\n",
    "params = {\n",
    "    \"variable_pairs\": variable_pairs,\n",
    "    \"loan_status_filter\": None\n",
    "}\n",
    "\n",
    "metric = BivariateScatterPlots(test_context, params=params)\n",
    "metric.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bivariate Histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from validmind.vm_models import Figure, Metric\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BivariateHistograms(Metric):\n",
    "    \"\"\"\n",
    "    Generates a visual analysis of categorical data by plotting bivariate histograms.\n",
    "    The input dataset and variable_pairs are required.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"bivariate_histograms\"\n",
    "    required_context = [\"dataset\"]\n",
    "    default_params = {\"variable_pairs\": None, \"loan_status_filter\": None}\n",
    "\n",
    "    def plot_bivariate_histogram(self, variable_pairs, loan_status_filter):\n",
    "        figures = []\n",
    "        palette = {0: (0.5, 0.5, 0.5, 0.8), 1: 'tab:red'}\n",
    "\n",
    "        for x, y in variable_pairs.items():\n",
    "            df = self.dataset.df\n",
    "            if loan_status_filter:\n",
    "                df = df[df[\"loan_status\"] == loan_status_filter]\n",
    "\n",
    "            fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "            for ax, var in zip(axes, [x, y]):\n",
    "                for loan_status, color in palette.items():\n",
    "                    subset = df[df['loan_status'] == loan_status]\n",
    "                    sns.histplot(subset[var],\n",
    "                                 ax=ax, \n",
    "                                 color=color,\n",
    "                                 edgecolor=None, \n",
    "                                 kde=True, \n",
    "                                 label='Default' if loan_status else 'Non-default')\n",
    "\n",
    "                ax.set_title(f\"Histogram of {var} by loan status\")\n",
    "                ax.set_xlabel(var)\n",
    "                ax.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            figures.append(\n",
    "                Figure(\n",
    "                    for_object=self, key=f\"{self.key}:{x}_{y}\", figure=plt.figure()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        return figures\n",
    "\n",
    "    def run(self):\n",
    "        variable_pairs = self.params[\"variable_pairs\"]\n",
    "        loan_status_filter = self.params[\"loan_status_filter\"]\n",
    "\n",
    "        figures = self.plot_bivariate_histogram(variable_pairs, loan_status_filter)\n",
    "\n",
    "        return self.cache_results(figures=figures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_pairs = {'int_rate': 'annual_inc', \n",
    "                  'funded_amnt_inv': 'dti', \n",
    "                  'annual_inc': 'funded_amnt_inv',\n",
    "                  'loan_amnt': 'int_rate',\n",
    "                  'int_rate': 'annual_inc',\n",
    "                  'earliest_cr_line': 'int_rate'}\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"variable_pairs\": variable_pairs,\n",
    "    \"loan_status_filter\": None\n",
    "}\n",
    "\n",
    "metric = BivariateHistograms(test_context, params=params)\n",
    "metric.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Analysis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.data_validation.PearsonCorrelationMatrix import PearsonCorrelationMatrix\n",
    "\n",
    "metric = PearsonCorrelationMatrix(test_context)\n",
    "metric.run()\n",
    "metric.result.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-eEL8LtKG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
