{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Dataset Test Suite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Time Series Data Validation Demo notebook aims to demonstrate the application of various data validation tests using the **ValidMind MRM Platform** and **Developer Framework**. Ensuring the quality and an a robust exploratory data analysis of time series data is essential for accurate model predictions and robust decision-making processes.\n",
    "\n",
    "In this demo, we will walk through different **data validation suites of tests** tailored for time series data, showcasing how these tools can assist you in identifying potential issues and inconsistencies in the data. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup \n",
    "\n",
    "Prepare the environment for our analysis. First, **import** all necessary libraries and modules required for our analysis. Next, **connect** to the ValidMind MRM platform, which provides a comprehensive suite of tools and services for model validation.\n",
    "\n",
    "Finally, define and **configure** the specific use case we are working on by setting up any required parameters, data sources, or other settings that will be used throughout the analysis. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key and secret from environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv .env\n",
    "\n",
    "# ValidMind libraries \n",
    "import validmind as vm\n",
    "from validmind.datasets.regression import (\n",
    "    identify_frequencies, \n",
    "    resample_to_common_frequency\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the ValidMind Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ValidMind. Project: Customer Churn Model - Initial Validation (clhhz04x40000wcy6shay2oco)\n"
     ]
    }
   ],
   "source": [
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  project = \"clhhz04x40000wcy6shay2oco\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find All Test Suites and Plans Available in the Developer Framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the **test suites** and **test plans** available in the developer framework by calling the following functions:\n",
    "\n",
    "- All test suites: `vm.test_suites.list_suites()`\n",
    "- All test plans: `vm.test_plans.list_plans()`\n",
    "- Describe a test plan: `vm.test_plans.describe_plan(\"time_series_data_quality\")`\n",
    "- List all available tests: `vm.test_plans.list_tests()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>ID                                </th><th>Name                           </th><th>Description                                      </th><th>Test Plans                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>binary_classifier_full_suite      </td><td>BinaryClassifierFullSuite      </td><td>Full test suite for binary classification models.</td><td>tabular_dataset_description, tabular_data_quality, binary_classifier_metrics, binary_classifier_validation, binary_classifier_model_diagnosis</td></tr>\n",
       "<tr><td>binary_classifier_model_validation</td><td>BinaryClassifierModelValidation</td><td>Test suite for binary classification models.     </td><td>binary_classifier_metrics, binary_classifier_validation, binary_classifier_model_diagnosis                                                   </td></tr>\n",
       "<tr><td>tabular_dataset                   </td><td>TabularDataset                 </td><td>Test suite for tabular datasets.                 </td><td>tabular_dataset_description, tabular_data_quality                                                                                            </td></tr>\n",
       "<tr><td>time_series_dataset               </td><td>TimeSeriesDataset              </td><td>Test suite for time series datasets.             </td><td>time_series_data_quality, time_series_univariate, time_series_multivariate                                                                   </td></tr>\n",
       "<tr><td>time_series_model_validation      </td><td>TimeSeriesModelValidation      </td><td>Test suite for time series model validation.     </td><td>regression_model_performance, regression_models_comparison, time_series_forecast                                                             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>ID                                </th><th>Name                           </th><th>Description                                      </th><th>Test Plans                                                                                                                                   </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>binary_classifier_full_suite      </td><td>BinaryClassifierFullSuite      </td><td>Full test suite for binary classification models.</td><td>tabular_dataset_description, tabular_data_quality, binary_classifier_metrics, binary_classifier_validation, binary_classifier_model_diagnosis</td></tr>\\n<tr><td>binary_classifier_model_validation</td><td>BinaryClassifierModelValidation</td><td>Test suite for binary classification models.     </td><td>binary_classifier_metrics, binary_classifier_validation, binary_classifier_model_diagnosis                                                   </td></tr>\\n<tr><td>tabular_dataset                   </td><td>TabularDataset                 </td><td>Test suite for tabular datasets.                 </td><td>tabular_dataset_description, tabular_data_quality                                                                                            </td></tr>\\n<tr><td>time_series_dataset               </td><td>TimeSeriesDataset              </td><td>Test suite for time series datasets.             </td><td>time_series_data_quality, time_series_univariate, time_series_multivariate                                                                   </td></tr>\\n<tr><td>time_series_model_validation      </td><td>TimeSeriesModelValidation      </td><td>Test suite for time series model validation.     </td><td>regression_model_performance, regression_models_comparison, time_series_forecast                                                             </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_suites.list_suites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>ID                               </th><th>Name                       </th><th>Description                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>binary_classifier_metrics        </td><td>BinaryClassifierMetrics    </td><td>Test plan for sklearn classifier metrics                                   </td></tr>\n",
       "<tr><td>binary_classifier_validation     </td><td>BinaryClassifierPerformance</td><td>Test plan for sklearn classifier models                                    </td></tr>\n",
       "<tr><td>binary_classifier_model_diagnosis</td><td>BinaryClassifierDiagnosis  </td><td>Test plan for sklearn classifier model diagnosis tests                     </td></tr>\n",
       "<tr><td>tabular_dataset_description      </td><td>TabularDatasetDescription  </td><td>Test plan to extract metadata and descriptive\n",
       "    statistics from a tabular dataset                                                                            </td></tr>\n",
       "<tr><td>tabular_data_quality             </td><td>TabularDataQuality         </td><td>Test plan for data quality on tabular datasets                             </td></tr>\n",
       "<tr><td>time_series_data_quality         </td><td>TimeSeriesDataQuality      </td><td>Test plan for data quality on time series datasets                         </td></tr>\n",
       "<tr><td>time_series_univariate           </td><td>TimeSeriesUnivariate       </td><td>Test plan to perform time series univariate analysis.                      </td></tr>\n",
       "<tr><td>time_series_multivariate         </td><td>TimeSeriesMultivariate     </td><td>Test plan to perform time series multivariate analysis.                    </td></tr>\n",
       "<tr><td>time_series_forecast             </td><td>TimeSeriesForecast         </td><td>Test plan to perform time series forecast tests.                           </td></tr>\n",
       "<tr><td>regression_model_performance     </td><td>RegressionModelPerformance </td><td>Test plan for performance metric of regression model of statsmodels library</td></tr>\n",
       "<tr><td>regression_models_comparison     </td><td>RegressionModelsComparison </td><td>Test plan for metrics comparison of regression model of statsmodels library</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>ID                               </th><th>Name                       </th><th>Description                                                                </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>binary_classifier_metrics        </td><td>BinaryClassifierMetrics    </td><td>Test plan for sklearn classifier metrics                                   </td></tr>\\n<tr><td>binary_classifier_validation     </td><td>BinaryClassifierPerformance</td><td>Test plan for sklearn classifier models                                    </td></tr>\\n<tr><td>binary_classifier_model_diagnosis</td><td>BinaryClassifierDiagnosis  </td><td>Test plan for sklearn classifier model diagnosis tests                     </td></tr>\\n<tr><td>tabular_dataset_description      </td><td>TabularDatasetDescription  </td><td>Test plan to extract metadata and descriptive\\n    statistics from a tabular dataset                                                                            </td></tr>\\n<tr><td>tabular_data_quality             </td><td>TabularDataQuality         </td><td>Test plan for data quality on tabular datasets                             </td></tr>\\n<tr><td>time_series_data_quality         </td><td>TimeSeriesDataQuality      </td><td>Test plan for data quality on time series datasets                         </td></tr>\\n<tr><td>time_series_univariate           </td><td>TimeSeriesUnivariate       </td><td>Test plan to perform time series univariate analysis.                      </td></tr>\\n<tr><td>time_series_multivariate         </td><td>TimeSeriesMultivariate     </td><td>Test plan to perform time series multivariate analysis.                    </td></tr>\\n<tr><td>time_series_forecast             </td><td>TimeSeriesForecast         </td><td>Test plan to perform time series forecast tests.                           </td></tr>\\n<tr><td>regression_model_performance     </td><td>RegressionModelPerformance </td><td>Test plan for performance metric of regression model of statsmodels library</td></tr>\\n<tr><td>regression_models_comparison     </td><td>RegressionModelsComparison </td><td>Test plan for metrics comparison of regression model of statsmodels library</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.list_plans()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conigure your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from validmind.datasets.classification import lending_club as demo_dataset\n",
    "from validmind.datasets.regression import fred as demo_dataset\n",
    "\n",
    "target_column = demo_dataset.target_column\n",
    "feature_columns = demo_dataset.feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into test and training \n",
    "df = demo_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MORTGAGE30US</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEDFUNDS</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS10</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Variable Frequency\n",
       "0  MORTGAGE30US      None\n",
       "1      FEDFUNDS        MS\n",
       "2          GS10        MS\n",
       "3        UNRATE        MS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequencies = identify_frequencies(df)\n",
    "display(frequencies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>GS10</th>\n",
       "      <th>UNRATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-03-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06</th>\n",
       "      <td>6.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13</th>\n",
       "      <td>6.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-20</th>\n",
       "      <td>6.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>6.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3551 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MORTGAGE30US  FEDFUNDS  GS10  UNRATE\n",
       "DATE                                            \n",
       "1947-01-01           NaN       NaN   NaN     NaN\n",
       "1947-02-01           NaN       NaN   NaN     NaN\n",
       "1947-03-01           NaN       NaN   NaN     NaN\n",
       "1947-04-01           NaN       NaN   NaN     NaN\n",
       "1947-05-01           NaN       NaN   NaN     NaN\n",
       "...                  ...       ...   ...     ...\n",
       "2023-04-01           NaN       NaN  3.46     NaN\n",
       "2023-04-06          6.28       NaN   NaN     NaN\n",
       "2023-04-13          6.27       NaN   NaN     NaN\n",
       "2023-04-20          6.39       NaN   NaN     NaN\n",
       "2023-04-27          6.43       NaN   NaN     NaN\n",
       "\n",
       "[3551 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3551 entries, 1947-01-01 to 2023-04-27\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   MORTGAGE30US  2718 non-null   float64\n",
      " 1   FEDFUNDS      825 non-null    float64\n",
      " 2   GS10          841 non-null    float64\n",
      " 3   UNRATE        903 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 138.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of Raw Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run the Time Series Dataset Test Suite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7e874559c64a24aab99bca3e071490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Running test suite...'), IntProgress(value=0, max=32)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
      "No frequency could be inferred for variable 'MORTGAGE30US'. Skipping seasonal decomposition and plots for this variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of FEDFUNDS: MS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of GS10: MS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of UNRATE: MS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MORTGAGE30US is not stationary. Results may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: GS10 is not stationary. Results may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MORTGAGE30US is not stationary. Results may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: GS10 is not stationary. Results may be inaccurate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef207a70be664443a4a42e2100d2b2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Test Suite Results: <i style=\"color: #DE257E\">Time Series Dataset</i></h2><hr>'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=df,\n",
    "    target_column=demo_dataset.target_column,\n",
    ")\n",
    "\n",
    "full_suite = vm.run_test_suite(\n",
    "    \"time_series_dataset\",\n",
    "    dataset=vm_dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the frequencies of each variable in the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = identify_frequencies(df)\n",
    "display(frequencies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Frequency Missmatches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle frequencies by resampling all variables to a common frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = resample_to_common_frequency(df, common_frequency=demo_dataset.frequency)\n",
    "frequencies = identify_frequencies(preprocessed_df)\n",
    "display(frequencies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run the Time Series Dataset Test Suite**\n",
    "\n",
    "Run the same suite again after handling frequencies.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=preprocessed_df,\n",
    "    target_column=demo_dataset.target_column,\n",
    ")\n",
    "\n",
    "full_suite = vm.run_test_suite(\n",
    "    \"time_series_dataset\",\n",
    "    dataset=vm_dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle the missing values by droping all the `nan` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = preprocessed_df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run the Time Series Dataset Test Suite**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the same test suite to check there are no missing values and frequencies of all variables are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=preprocessed_df,\n",
    "    target_column=demo_dataset.target_column,\n",
    ")\n",
    "\n",
    "full_suite = vm.run_test_suite(\n",
    "    \"time_series_dataset\",\n",
    "    dataset=vm_dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Stationarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle stationarity by taking the first difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = preprocessed_df.diff().fillna(method='bfill')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Run the Time Series Dataset Test Suite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=preprocessed_df,\n",
    "    target_column=demo_dataset.target_column,\n",
    ")\n",
    "\n",
    "full_suite = vm.run_test_suite(\n",
    "    \"time_series_dataset\",\n",
    "    dataset=vm_dataset,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-eEL8LtKG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
