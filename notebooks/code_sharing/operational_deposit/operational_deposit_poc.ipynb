{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operational Deposit Model Documentation Demo\n",
    "\n",
    "0. Explore ValidMind developer framework\n",
    "1. Data quality tests\n",
    "2. Segmentation of data\n",
    "3. Custom tests\n",
    "4. Review model document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc2_'></a>\n",
    "\n",
    "## About ValidMind\n",
    "\n",
    "ValidMind is a platform for managing model risk, including risk associated with AI and statistical models.\n",
    "\n",
    "You use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on model documentation. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
    "\n",
    "<a id='toc2_1_'></a>\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "This notebook assumes you have basic familiarity with Python, including an understanding of how functions work. If you are new to Python, you can still run the notebook but we recommend further familiarizing yourself with the language. \n",
    "\n",
    "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html).\n",
    "\n",
    "<a id='toc2_2_'></a>\n",
    "\n",
    "### New to ValidMind?\n",
    "\n",
    "If you haven't already seen our [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/developer/get-started-developer-framework.html), we recommend you explore the available resources for developers at some point. There, you can learn more about documenting models, find code samples, or read our developer reference.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #f7e4ee; color: black; border: 1px solid black;\"><b>For access to all features available in this notebook, create a free ValidMind account.</b>\n",
    "<br></br>\n",
    "Signing up is FREE â€” <a href=\"https://docs.validmind.ai/guide/configuration/register-with-validmind.html\"><b>Register with ValidMind</b></a></div>\n",
    "\n",
    "<a id='toc2_3_'></a>\n",
    "\n",
    "![Dataset based test architecture](./dataset_image.png)\n",
    "![Model based test architecture](./model_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "Let's go ahead and install the `validmind` library if its not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VM_OVERRIDE_METADATA\"] = \"true\"\n",
    "os.environ[\"VALIDMIND_LLM_DESCRIPTIONS_ENABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc4_'></a>\n",
    "\n",
    "## Initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, [log in to ValidMind](https://docs.validmind.ai/guide/configuration/log-in-to-validmind.html).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details, making sure to select **Time Series Forecasting** as the template and **Credit Risk - Underwriting - Loan** as the use case, and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/model-inventory/register-models-in-inventory.html))\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your code snippet\n",
    "\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(api_host=\"...\", api_key=\"...\", api_secret=\"...\", model=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before learning how to run tests, let's explore the list of all available tests in the ValidMind Developer Framework. You can see that the documentation template for this model has references to some of the test IDs listed below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.list_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data quality assessments by running a few individual tests related to data assessment. You will use the `vm.tests.list_tests()` function introduced above in combination with `vm.tests.list_tags()` and `vm.tests.list_tasks()` to find which prebuilt tests are relevant for data quality assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available tags\n",
    "sorted(vm.tests.list_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available tasks\n",
    "sorted(vm.tests.list_tasks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass `tags` and `tasks` as parameters to the `vm.tests.list_tests()` function to filter the tests based on the tags and task types. For example, to find tests related to tabular data quality for classification models, you can call `list_tests()` like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.list_tests(task=\"classification\", tags=[\"tabular_data\", \"data_quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_csv(\"./datasets/odm_data_example/synthetic_data.csv\")\n",
    "print(f\"Columns {list(raw_df.columns)}\")\n",
    "print(f\"Size {list(raw_df.shape)}\")\n",
    "\n",
    "raw_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data validation\n",
    "\n",
    "Now that we have loaded our dataset, we can go ahead and run some data validation tests right away to start assessing and documenting the quality of our data. Since we are using a text dataset, we can use ValidMind's built-in array of text data quality tests to check that things like number of duplicates, missing values, and other common text data issues are not present in our dataset. We can also run some tests to check the sentiment and toxicity of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidMind objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_raw_ds = vm.init_dataset(\n",
    "    dataset=raw_df, input_id=\"raw_dataset\", target_column=\"cust_ipid_nm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.list_tests(filter=\"data_validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_ds_summary = vm.init_dataset(\n",
    "    dataset=raw_df.drop(\"bal_date\", axis=1),\n",
    "    input_id=\"raw_dataset\",\n",
    "    target_column=\"cust_ipid_nm\",\n",
    ")\n",
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.DatasetDescription\", dataset=vm_ds_summary\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "First, let's check for duplicates in our dataset. We can use the `validmind.data_validation.Duplicates` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.Duplicates\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Next, let's check for missing values in our dataset. We can use the `validmind.data_validation.MissingValues` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\"validmind.data_validation.MissingValues\", dataset=vm_raw_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique rows\n",
    "\n",
    "Next, let's check for unique rows in our dataset. We can use the `validmind.data_validation.UniqueRows` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\"validmind.data_validation.UniqueRows\", dataset=vm_raw_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High cardinality\n",
    "\n",
    "Next, let's check for high cardinality in our dataset. We can use the `validmind.data_validation.HighCardinality` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.HighCardinality\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness\n",
    "\n",
    "Next, let's check for skewness in our dataset. We can use the `validmind.data_validation.Skewness` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.Skewness\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Values\n",
    "\n",
    "Next, let's check for zeros values in our dataset. We can use the `validmind.data_validation.TooManyZeroValues` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.TooManyZeroValues\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "Next, let's check statistics of our dataset. We can use the `validmind.data_validation.DescriptiveStatistics` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.DescriptiveStatistics\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High pearson correlation\n",
    "\n",
    "Next, let's check person correlation of our dataset. We can use the `validmind.data_validation.HighPearsonCorrelation` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.HighPearsonCorrelation\", dataset=vm_raw_ds\n",
    ")\n",
    "result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation matrix\n",
    "\n",
    "Next, let's check person correlation matrix of our dataset. We can use the `validmind.data_validation.PearsonCorrelationMatrix` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.PearsonCorrelationMatrix\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation of clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = raw_df.drop(\n",
    "    columns=[\n",
    "        \"LOB_data\",\n",
    "        \"cust_id\",\n",
    "        \"bal_date\",\n",
    "        \"ult_parent_cust_ipid_no\",\n",
    "        \"ult_parent_cust_nm\",\n",
    "        \"client\",\n",
    "        \"subclient\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "target_column = \"cust_ipid_nm\"\n",
    "cluster_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "Let's build Kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.cluster import digits as demo_dataset\n",
    "\n",
    "cluster_df = cluster_df.dropna()\n",
    "train_df, validation_df, test_df = demo_dataset.preprocess(cluster_df)\n",
    "\n",
    "x_train = train_df.drop(target_column, axis=1)\n",
    "y_train = train_df[target_column]\n",
    "x_val = validation_df.drop(target_column, axis=1)\n",
    "y_val = validation_df[target_column]\n",
    "x_test = test_df.drop(target_column, axis=1)\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "\n",
    "x_train = pd.concat([x_train, x_val], axis=0)\n",
    "y_train = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "scale = False\n",
    "if scale:\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_val = scaler.fit_transform(x_val)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "\n",
    "n_clusters = 4\n",
    "model = KMeans(init=\"k-means++\", n_clusters=n_clusters, n_init=4)  # random_state=0\n",
    "model = model.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepate VM dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df, target_column=target_column, input_id=\"training_seg_dataset\"\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df, target_column=target_column, input_id=\"test_seg_dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_model = vm.init_model(model, input_id=\"kmean_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Prediction values can be attached using `assign_prediction` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(model=vm_model)\n",
    "vm_test_ds.assign_predictions(model=vm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Manual vs predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.ConfusionMatrix:training\",\n",
    "    inputs={\"dataset\": vm_train_ds, \"model\": vm_model},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.ConfusionMatrix:test\",\n",
    "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.HyperParametersTuning\",\n",
    "    inputs={\"dataset\": vm_train_ds, \"model\": vm_model},\n",
    "    params={\"param_grid\": {\"n_clusters\": range(3, 6)}},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.ClusterPerformanceMetrics\",\n",
    "    inputs={\"datasets\": (vm_train_ds, vm_test_ds), \"model\": vm_model},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No of clusters optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.KMeansClustersOptimization\",\n",
    "    inputs={\"dataset\": vm_train_ds, \"model\": vm_model},\n",
    "    params={\n",
    "        \"n_clusters\": range(2, 8),\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operational deposit  model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational deposit model compuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operational_deposit_df = raw_df.copy()\n",
    "target_column = \"cust_ipid_nm\"\n",
    "\n",
    "\n",
    "# Eod_outflow_ratio\n",
    "# Step 4: Statistical Analysis\n",
    "def calculate_eod_outflow_ratio(df):\n",
    "    df[\"eod_outflow_ratio\"] = df[\"EOD\"] / df[\"Total_Outflow\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "operational_deposit_df = calculate_eod_outflow_ratio(operational_deposit_df)\n",
    "\n",
    "\n",
    "# Step 5: Model Implementation\n",
    "def rolling_average(df, window=30):\n",
    "    df[\"rolling_eod_balance\"] = (\n",
    "        df.groupby(\"cust_ipid_nm\")[\"EOD\"]\n",
    "        .rolling(window=window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"rolling_daily_outflow\"] = (\n",
    "        df.groupby(\"cust_ipid_nm\")[\"Total_Outflow\"]\n",
    "        .rolling(window=window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "operational_deposit_df = rolling_average(operational_deposit_df)\n",
    "\n",
    "# # Step 6: Output Generation\n",
    "# def generate_outputs(df):\n",
    "#     output_df = df.groupby(['cust_ipid_nm', 'subclient']).agg({\n",
    "#         'rolling_eod_balance': 'last',\n",
    "#         'rolling_daily_outflow': 'last'\n",
    "#     }).reset_index()\n",
    "#     output_df['operational_core'] = output_df['rolling_eod_balance'] / output_df['rolling_daily_outflow']\n",
    "#     return output_df\n",
    "\n",
    "# raw_df = generate_outputs(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare VM dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.cluster import digits as demo_dataset\n",
    "\n",
    "operational_deposit_df = operational_deposit_df.dropna()\n",
    "\n",
    "x_train = operational_deposit_df.drop(target_column, axis=1)\n",
    "y_train = operational_deposit_df[target_column]\n",
    "\n",
    "vm_od_ds = vm.init_dataset(\n",
    "    dataset=operational_deposit_df, input_id=\"od_dataset\", target_column=\"cust_ipid_nm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VM model\n",
    "VM provides flexibility to generate model as per the use case requirement. Here, it's simple we treat prediction value as value of column `rolling_daily_outflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operational_deposit(input):\n",
    "\n",
    "    return input[\"rolling_daily_outflow\"]\n",
    "\n",
    "\n",
    "vm_od_model = vm.init_model(\n",
    "    input_id=\"operational_deposit\", predict_fn=operational_deposit\n",
    ")\n",
    "vm_od_ds.assign_predictions(\n",
    "    model=vm_od_model, prediction_column=\"rolling_daily_outflow\"\n",
    ")\n",
    "print(vm_od_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External test provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import LocalTestProvider\n",
    "\n",
    "tests_folder = \"tests\"\n",
    "# initialize the test provider with the tests folder we created earlier\n",
    "my_test_provider = LocalTestProvider(tests_folder)\n",
    "\n",
    "vm.tests.register_test_provider(\n",
    "    namespace=\"demo_test_provider\",\n",
    "    test_provider=my_test_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple custom test\n",
    "Let's plot timeseries line plot by grouping a specific column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"demo_test_provider.TimeseriesGroupbyPlot\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"cust_ipid_nm\",\n",
    "        \"y_column\": \"Total_Outflow\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"my_test_provider.TimeseriesGroupbyPlot:Total_Outflow\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"client\",\n",
    "        \"y_column\": \"Total_Outflow\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"my_test_provider.TimeseriesGroupbyPlot:eod_outflow_ratio\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"subclient\",\n",
    "        \"y_column\": \"eod_outflow_ratio\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"my_test_provider.TimeseriesGroupbyPlot:rolling_eod_balance\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"subclient\",\n",
    "        \"y_column\": \"rolling_eod_balance\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc8_'></a>\n",
    "\n",
    "## Where to go from here\n",
    "\n",
    "In this notebook you have learned the end-to-end process to document a model with the ValidMind Developer Framework, running through some very common scenarios in a typical model development setting:\n",
    "\n",
    "- Running out-of-the-box tests\n",
    "- Documenting your model by adding evidence to model documentation\n",
    "- Extending the capabilities of the Developer Framework by implementing custom tests\n",
    "- Ensuring that the documentation is complete by running all tests in the documentation template\n",
    "\n",
    "As a next step, you can explore the following notebooks to get a deeper understanding on how the developer framework allows you generate model documentation for any use case:\n",
    "\n",
    "<a id='toc8_1_'></a>\n",
    "\n",
    "### Use cases\n",
    "\n",
    "- [Application scorecard demo](../code_samples/credit_risk/application_scorecard_demo.ipynb)\n",
    "- [Linear regression documentation demo](../code_samples/regression/quickstart_regression_full_suite.ipynb)\n",
    "- [LLM model documentation demo](../code_samples/nlp_and_llm/foundation_models_integration_demo.ipynb)\n",
    "\n",
    "<a id='toc8_2_'></a>\n",
    "\n",
    "### More how-to guides and code samples\n",
    "\n",
    "- [Explore available tests in detail](../how_to/explore_tests.ipynb)\n",
    "- [In-depth guide for implementing custom tests](../code_samples/custom_tests/implement_custom_tests.ipynb)\n",
    "- [In-depth guide to external test providers](../code_samples/custom_tests/integrate_external_test_providers.ipynb)\n",
    "- [Configuring dataset features](../how_to/configure_dataset_features.ipynb)\n",
    "- [Introduction to unit and composite metrics](../how_to/run_unit_metrics.ipynb)\n",
    "\n",
    "<a id='toc8_3_'></a>\n",
    "\n",
    "### Discover more learning resources\n",
    "\n",
    "All notebook samples can be found in the following directories of the Developer Framework GitHub repository:\n",
    "\n",
    "- [Code samples](https://github.com/validmind/developer-framework/tree/main/notebooks/code_samples)\n",
    "- [How-to guides](https://github.com/validmind/developer-framework/tree/main/notebooks/how_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
