{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lifetime PD Model POC"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the client library\n",
        "\n",
        "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
        "\n",
        "Get your code snippet:\n",
        "\n",
        "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
        "\n",
        "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
        "\n",
        "3. Enter the model details and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/register-models-in-model-inventory.html))\n",
        "\n",
        "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
        "\n",
        "Next, replace this placeholder with your own code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import validmind as vm\n",
        "\n",
        "vm.init(\n",
        "  api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
        "  api_key = \"...\",\n",
        "  api_secret = \"...\",\n",
        "  project = \"...\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from notebooks.probability_of_default.helpers.Developer import Developer\n",
        "from notebooks.probability_of_default.helpers.scorecard_tasks import *\n",
        "from notebooks.probability_of_default.helpers.model_development_tasks import *"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "default_column = 'default'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Credit Risk Scorecard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "developer = Developer()\n",
        "scorecard = developer.load_objects_from_pickle(\"datasets/scorecard_data_and_models.pkl\")\n",
        "\n",
        "df_train_feateng = scorecard[\"df_train_feateng\"]\n",
        "df_test_feateng = scorecard[\"df_test_feateng\"]\n",
        "\n",
        "model_fit_final = scorecard[\"model_fit_final\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create ValidMind Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.vm_models.test_context import TestContext\n",
        "\n",
        "vm_df_train = vm.init_dataset(\n",
        "    dataset=df_train_feateng,\n",
        "    target_column=default_column)\n",
        "vm_df_test = vm.init_dataset(\n",
        "    dataset=df_test_feateng,\n",
        "    target_column=default_column)\n",
        "\n",
        "vm_model_fit_final = vm.init_model(\n",
        "    model = model_fit_final,\n",
        "    train_ds=vm_df_train,\n",
        "    test_ds=vm_df_test)\n",
        "\n",
        "test_context_models_fit_final = TestContext(models = [vm_model_fit_final])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Description"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Macroeconomic Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Target Variable**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**DRSFRMACBS (Delinquency Rate on Single-Family Residential Mortgages, Booked in Domestic Offices, All Commercial Banks)**: This stands for Delinquency Rate on Single-Family Residential Mortgages, Booked in Domestic Offices, All Commercial Banks. It reflects the percentage of loans that are past due.\n",
        "\n",
        "Why is the delinquency rate a good target variable for building a lifetime PD and ECL Models? \n",
        "  \n",
        "- Measure of credit risk: Delinquency rate directly captures the proportion of borrowers who are behind on their payments. It's a straightforward and intuitive measure of credit risk.\n",
        "- Relevance to ECL: ECL requires a forward-looking assessment of credit risk. Delinquencies can provide early warning signals about loans that might eventually result in credit losses, making it directly relevant to ECL modeling."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Features**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **GDPC1 (Real Gross Domestic Product)**: Economic downturns, indicated by shrinking GDP, can lead to an increase in loan delinquencies as borrowers may face financial difficulties. A growing economy, on the other hand, may correlate with fewer delinquencies.\n",
        "\n",
        "- **UNRATE (U.S. Unemployment Rate)**: A rise in unemployment rates usually correlates with an increase in delinquencies. When people lose jobs, they may have difficulty meeting financial obligations, including loan payments.\n",
        "\n",
        "- **MORTGAGE30US (30-year fixed rate mortgage average)**: The interest rate environment can have an influence on the propensity for delinquencies, especially for adjustable-rate loans. High-interest rates can lead to larger monthly payments, increasing the chances of delinquency for some borrowers.\n",
        "\n",
        "- **CPIAUCSL (Consumer Price Index for All Urban Consumers)**: Inflation can erode purchasing power, making it more challenging for borrowers to meet their debt obligations.\n",
        "\n",
        "- **FEDFUNDS (Effective federal funds rate)**: The short-term interest rate can impact borrowing costs. It might indirectly influence delinquency rates, especially if borrowers are sensitive to changes in their loan rates or if they have loans with variable rates.\n",
        "\n",
        "- **GS3, GS5, GS10 (Treasury constant maturity rates)**: These rates can serve as a proxy for the broader interest rate environment. They can influence both the borrowing cost and the appetite of financial institutions to lend. Fluctuations in these rates can potentially impact delinquency rates.\n",
        "\n",
        "- **CSUSHPISA (S&P/Case-Shiller U.S. National Home Price Index)**: For mortgage loans, changes in home values can play a significant role. Borrowers are more likely to default on a mortgage if the value of the underlying property falls below the loan amount."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.data_validation.TimeSeriesOutliers import TimeSeriesOutliers\n",
        "\n",
        "vm_df = vm.init_dataset(\n",
        "    dataset=df_macro_micro_raw,\n",
        "    target_column=macro_to_micro_target_column)\n",
        "\n",
        "test_context = TestContext(dataset=vm_df)\n",
        "\n",
        "params = {\"zscore_threshold\": 3}\n",
        "\n",
        "metric = TimeSeriesOutliers(test_context, params)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.data_validation.TimeSeriesMissingValues import TimeSeriesMissingValues\n",
        "\n",
        "params = {\"min_threshold\": 2}\n",
        "\n",
        "metric = TimeSeriesMissingValues(test_context, params)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.data_validation.TimeSeriesFrequency import TimeSeriesFrequency\n",
        "\n",
        "metric = TimeSeriesFrequency(test_context)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GLM Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model_fit_final.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.model_validation.statsmodels.RegressionModelsCoeffs import RegressionModelsCoeffs\n",
        "\n",
        "metric = RegressionModelsCoeffs(test_context_models_fit_final)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.model_validation.statsmodels.RegressionCoeffsPlot import RegressionCoeffsPlot\n",
        "\n",
        "metric = RegressionCoeffsPlot(test_context_models_fit_final)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Macroeconomic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove COVID years to avoid outliers\n",
        "df_macro_micro_filtered = df_macro_micro_raw[df_macro_micro_raw.index <= '2019-12-31']\n",
        "\n",
        "# Sample frequencies to Monthly\n",
        "resampled_df = df_macro_micro_filtered.resample(\"QS-OCT\").last()\n",
        "\n",
        "# Remove all missing values\n",
        "nona_df = resampled_df.dropna()\n",
        "\n",
        "# Take the first different across all variables\n",
        "preprocessed_df = nona_df.diff().dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_df = vm.init_dataset(\n",
        "    dataset=preprocessed_df,\n",
        "    target_column=macro_to_micro_target_column)\n",
        "\n",
        "test_context = TestContext(dataset=vm_df)\n",
        "\n",
        "params = {\"min_threshold\": 2}\n",
        "\n",
        "metric = TimeSeriesMissingValues(test_context, params)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = TimeSeriesFrequency(test_context)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.data_validation.TimeSeriesLinePlot import TimeSeriesLinePlot\n",
        "\n",
        "metric = TimeSeriesLinePlot(test_context)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.data_validation.LaggedCorrelationHeatmap import LaggedCorrelationHeatmap\n",
        "\n",
        "metric = LaggedCorrelationHeatmap(test_context)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests.data_validation.EngleGrangerCoint import EngleGrangerCoint\n",
        "\n",
        "metric = EngleGrangerCoint(test_context)\n",
        "metric.run()\n",
        "metric.result.log()\n",
        "metric.result.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_selection_df = preprocessed_df[macro_to_micro_preliminary_features + macro_to_micro_target_column]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Split the data into predictors and target\n",
        "X = feature_selection_df.drop(columns=macro_to_micro_target_column)\n",
        "y = feature_selection_df[macro_to_micro_target_column]\n",
        "\n",
        "# Add a constant to the predictors\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the summary statistics of the regression model\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_features = ['UNRATE', 'FEDFUNDS', 'CSUSHPISA']\n",
        "\n",
        "final_features_df = feature_selection_df[final_features + macro_to_micro_target_column]\n",
        "\n",
        "# Split the data into predictors and target\n",
        "X = final_features_df.drop(columns=macro_to_micro_target_column)\n",
        "y = final_features_df[macro_to_micro_target_column]\n",
        "\n",
        "# Add a constant to the predictors\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the summary statistics of the regression model\n",
        "print(model.summary())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dev-framework",
      "language": "python",
      "name": "dev-framework"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
