{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortality Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, [log in to ValidMind](https://docs.validmind.ai/guide/configuration/log-in-to-validmind.html).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details, making sure to select **Binary classification** as the template and **Marketing/Sales - Attrition/Churn Management** as the use case, and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/model-inventory/register-models-in-inventory.html))\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your code snippet\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "    api_host=\"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "    api_key=\"...\",\n",
    "    api_secret=\"...\",\n",
    "    model=\"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Demo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample file\n",
    "sample_df = pd.read_csv('./Data/ILEC 2009-16 20200123 sample_small.csv',\n",
    "                        usecols=['Observation_Year', 'Gender', 'Smoker_Status',\n",
    "                                 'Insurance_Plan', 'Duration', 'Attained_Age', 'SOA_Guaranteed_Level_Term_Period',\n",
    "                                 'Face_Amount_Band', 'Preferred_Class',\n",
    "                                 'Number_Of_Deaths', 'Policies_Exposed',\n",
    "                                 'SOA_Anticipated_Level_Term_Period', 'SOA_Post_level_Term_Indicator',\n",
    "                                 'Expected_Death_QX2015VBT_by_Policy',\n",
    "                                 'Issue_Age', 'Issue_Year'])\n",
    "\n",
    "# target variable\n",
    "sample_df['mort'] = sample_df['Number_Of_Deaths'] / sample_df['Policies_Exposed']\n",
    "\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter pipeline\n",
    "df = sample_df[(sample_df.Expected_Death_QX2015VBT_by_Policy != 0)\n",
    "               & (sample_df.Smoker_Status != 'Unknown')\n",
    "               & (sample_df.Insurance_Plan == ' Term')\n",
    "               & (-sample_df.Preferred_Class.isna())\n",
    "               & (sample_df.Attained_Age >= 18)\n",
    "               & (sample_df.Issue_Year >= 1980)\n",
    "               & (sample_df.SOA_Post_level_Term_Indicator == \"Within Level Term\")\n",
    "               & (sample_df.SOA_Anticipated_Level_Term_Period != \"Unknown\")\n",
    "               & (sample_df.mort < 1)]\n",
    "\n",
    "print(f'Count: {df.shape[0]}')\n",
    "print()\n",
    "\n",
    "# describe data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.test_suites import register_test_suite\n",
    "from validmind.test_suites import register_test_suite\n",
    "from validmind.vm_models import TestPlan, TestSuite\n",
    "\n",
    "\n",
    "class TabularDataQualityExtra(TestPlan):\n",
    "    \"\"\"\n",
    "    Expanded test plan for data quality on tabular datasets\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"tabular_data_quality_extra\"\n",
    "    tests = [\n",
    "        \"validmind.data_validation.FeatureTargetCorrelationPlot\",\n",
    "        \"validmind.data_validation.IQROutliersBarPlot\",\n",
    "        \"validmind.data_validation.IQROutliersTable\",\n",
    "        \"validmind.data_validation.ScatterPlot\",\n",
    "        \"validmind.data_validation.TabularCategoricalBarPlots\",\n",
    "        \"validmind.data_validation.TabularNumericalHistograms\",\n",
    "    ]\n",
    "\n",
    "\n",
    "class CustomTabularDataset(TestSuite):\n",
    "    \"\"\"\n",
    "    Test suite for tabular datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"custom_tabular_dataset\"\n",
    "\n",
    "    test_suites = [\n",
    "        # \"tabular_dataset_description\",\n",
    "        # \"tabular_data_quality\",\n",
    "        \"tabular_data_quality_extra\",\n",
    "    ]\n",
    "\n",
    "\n",
    "register_test_suite(\"tabular_data_quality_extra\", TabularDataQualityExtra)\n",
    "register_test_suite(\"custom_tabular_dataset\", CustomTabularDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=df,\n",
    "    target_column=\"mort\",\n",
    ")\n",
    "\n",
    "tabular_suite = vm.run_test_suite(\n",
    "    \"custom_tabular_dataset\", dataset=vm_dataset, fail_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_vars = ['Observation_Year',\n",
    "            'Gender',\n",
    "            'Smoker_Status',\n",
    "            'Face_Amount_Band',\n",
    "            'Preferred_Class',\n",
    "            'SOA_Anticipated_Level_Term_Period']\n",
    "\n",
    "onehot = preprocessing.OneHotEncoder()\n",
    "results = onehot.fit_transform(df[cat_vars]).toarray()\n",
    "cat_vars_encoded = list(onehot.get_feature_names_out())\n",
    "df = pd.concat(\n",
    "    [df, pd.DataFrame(data=results, columns=cat_vars_encoded, index=df.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "Y = ['Number_Of_Deaths']\n",
    "\n",
    "# Predictors (aka Input Variables)\n",
    "X = cat_vars_encoded + ['Attained_Age', 'Duration', 'Const']\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "policies_exposed = train_df['Policies_Exposed']\n",
    "\n",
    "# add constant variable\n",
    "train_df['Const'] = 1\n",
    "test_df['Const'] = 1\n",
    "\n",
    "train_df = train_df[X + Y]\n",
    "test_df = test_df[X + Y]\n",
    "\n",
    "print(f'Train size: {train_df.shape[0]}, test size: {test_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM modeling 101\n",
    "\n",
    "In a generalized linear model (GLM), each outcome Y of the dependent variables is assumed to be generated from a particular distribution in an exponential family, a large class of probability distributions that includes the normal, binomial, Poisson and gamma distributions, among others. The mean, $μ$, of the distribution depends on the independent variables, X, through\n",
    "\n",
    "<center>${\\displaystyle \\operatorname {E} (\\mathbf {Y} |\\mathbf {X} )={\\boldsymbol {\\mu }}=g^{-1}(\\mathbf {X} {\\boldsymbol {\\beta }})}$</center>\n",
    "\n",
    "${\\displaystyle \\operatorname {E} (\\mathbf {Y} |\\mathbf {X} )={\\boldsymbol {\\mu }}=g^{-1}(\\mathbf {X} {\\boldsymbol {\\beta }})}$\n",
    "\n",
    "where:\n",
    "\n",
    "- $E(Y|X)$ is the expected value of $Y$ conditional on $X$\n",
    "- $Xβ$ is the linear predictor, a linear combination of unknown parameters $β$\n",
    "- $g$ is the link function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Poisson distribution with log link on count\n",
    "\n",
    "<i> Target Variable </i> = [Number_Of_Deaths]\n",
    "\n",
    "<i> Input Variables </i> =  [Observation_Year, Gender, Smoker_Status, Face_Amount_Band, Preferred_Class, Attained_Age, Duration, SOA_Anticipated_Level_Term_Period]\n",
    "\n",
    "As the <i> target variable</i> is a count measure, we will fit GLM with Poisson distribution and log link. \n",
    "\n",
    "The target variable is count, what we really fit the Poisson model to is mortality rate (count/exposure) with the use of offset. This is a common practice according to \n",
    "https://en.wikipedia.org/wiki/Poisson_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our choice for Link function is the Gaussian distribution for the nature of death frequency\n",
    "model = sm.GLM(endog=train_df[Y],\n",
    "               exog=train_df[X],\n",
    "               family=sm.families.Poisson(sm.families.links.log()),\n",
    "               freq_weights=policies_exposed,\n",
    "               offset=policies_exposed.apply(lambda x: np.log(x))\n",
    "               )\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training and testing datasets for model A\n",
    "vm_train_ds = vm.init_dataset(dataset=train_df, target_column=\"Number_Of_Deaths\")\n",
    "vm_test_ds = vm.init_dataset(dataset=test_df, target_column=\"Number_Of_Deaths\")\n",
    "\n",
    "vm_model_1 = vm.init_model(\n",
    "    model=res,\n",
    "    train_ds=vm_train_ds,\n",
    "    test_ds=vm_test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTestsExtra(TestPlan):\n",
    "    \"\"\"\n",
    "    Expanded test plan for regression models\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"regression_extra\"\n",
    "    tests = [\n",
    "        \"validmind.model_validation.statsmodels.RegressionCoeffsPlot\",\n",
    "    ]\n",
    "\n",
    "\n",
    "class RegressionSuite(TestSuite):\n",
    "    \"\"\"\n",
    "    Test suite for regression models.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"custom_regression_suite\"\n",
    "\n",
    "    test_suites = [\n",
    "        \"regression_extra\",\n",
    "        \"regression_model_description\",\n",
    "        \"regression_models_evaluation\",\n",
    "    ]\n",
    "\n",
    "\n",
    "register_test_suite(\"regression_extra\", RegressionTestsExtra)\n",
    "register_test_suite(\"custom_regression_suite\", RegressionSuite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_results = vm.run_test_suite(\n",
    "    \"custom_regression_suite\",\n",
    "    model=vm_model_1,\n",
    "    models=[vm_model_1]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dev Framework 3.9.16",
   "language": "python",
   "name": "dev-framework-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
