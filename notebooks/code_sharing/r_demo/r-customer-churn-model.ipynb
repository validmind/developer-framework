{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Customer Churn Model\n",
    "This notebook demonstrates the process of creating a customer churn model using R. We will use the XGBoost and logistic regression algorithms to create two separate models and compare their performance.\n",
    "\n",
    "The dataset used in this notebook is located at `../datasets/bank_customer_churn.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Requisites:\n",
    "\n",
    "#### install R using homebrew if you don't have it already:\n",
    "\n",
    "```bash\n",
    "brew install r\n",
    "```\n",
    "\n",
    "You additionally might need the following packages to run this notebook if you run into errors:\n",
    "\n",
    "```bash\n",
    "brew install harfbuzz fribidi libtiff libomp\n",
    "```\n",
    "\n",
    "#### Install the following packages in an R console:\n",
    "\n",
    "```R\n",
    "install.packages(\"xgboost\")\n",
    "install.packages(\"caret\")\n",
    "install.packages(\"pROC\")\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries\n",
    "First, we load the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# load the required libraries\n",
    "library(xgboost)\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Dataset\n",
    "Now, we import the dataset and preprocess it by removing irrelevant columns, converting categorical variables, and one-hot encoding certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "df <- read.csv(\"../datasets/bank_customer_churn.csv\", header = TRUE)\n",
    "\n",
    "# remove irrelevant columns\n",
    "df <- df %>% select(-c(RowNumber, CustomerId, Surname, CreditScore))\n",
    "\n",
    "# Convert the 'Gender' column to 0 or 1 (assuming \"Female\" should be 0 and \"Male\" should be 1)\n",
    "df$Gender <- ifelse(df$Gender == \"Female\", 0, 1)\n",
    "\n",
    "# one-hot encode categorical columns with caret\n",
    "df <- dummyVars(\" ~ .\", data = df) %>% predict(df)\n",
    "\n",
    "# remove GeographySpain since it causes multicollinearity\n",
    "df <- subset(df, select = -GeographySpain)\n",
    "\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "Next, we split the data into training\n",
    "and testing sets using a 70/30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "set.seed(123)\n",
    "train_index <- sample(1:nrow(df), size = round(0.7*nrow(df)), replace = FALSE)\n",
    "df_train <- df[train_index, ]\n",
    "df_test <- df[-train_index, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train and Test Datasets\n",
    "We save the train and test datasets as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# save the train and test datasets as csv files\n",
    "write.csv(df_train, file = \"r_churn_train.csv\", row.names = FALSE)\n",
    "write.csv(df_test, file = \"r_churn_test.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data to DMatrix Format\n",
    "We convert the data into DMatrix format, which is required by the XGBoost library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# convert data into DMatrix format\n",
    "dtrain <- xgb.DMatrix(data = df_train[,-c(11)], label = df_train[,\"Exited\"])\n",
    "dtest <- xgb.DMatrix(data = df_test[,-c(11)], label = df_test[,\"Exited\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up XGBoost Parameters\n",
    "We set up the XGBoost parameters to be used during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# set up XGBoost parameters\n",
    "params <- list(\n",
    "  objective = \"binary:logistic\",\n",
    "  eval_metric = \"auc\",\n",
    "  max_depth = 3,\n",
    "  eta = 0.1,\n",
    "  gamma = 0.5,\n",
    "  subsample = 0.8,\n",
    "  colsample_bytree = 0.8,\n",
    "  min_child_weight = 1,\n",
    "  nthread = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the XGBoost Model\n",
    "We train the XGBoost model using the parameters and data prepared earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# train the XGBoost model\n",
    "model <- xgb.train(\n",
    "  params = params,\n",
    "  data = dtrain,\n",
    "  nrounds = 100,\n",
    "  watchlist = list(train = dtrain, test = dtest),\n",
    "  early_stopping_rounds = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "We display a summary of the trained XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data\n",
    "We make predictions on the test data and calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "test_preds <- predict(model, dtest)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "test_preds_binary <- ifelse(test_preds > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy <- sum(test_preds_binary == df_test[,\"Exited\"])/nrow(df_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Tests\n",
    "We calculate the confusion matrix, precision, recall, F1 score, and ROC AUC for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm <- confusionMatrix(as.factor(test_preds_binary), as.factor(df_test[,\"Exited\"]))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[2, 1])\n",
    "recall <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[1, 2])\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "cat(\"Precision:\", precision, \"\\n\")\n",
    "cat(\"Recall:\", recall, \"\\n\")\n",
    "cat(\"F1 Score:\", f1_score, \"\\n\")\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_obj <- roc(df_test[,\"Exited\"], test_preds)\n",
    "roc_auc <- auc(roc_obj)\n",
    "cat(\"ROC AUC:\", roc_auc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "We save the trained XGBoost model as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# save the model (notice the .json extension, we could also save it as .bin)\n",
    "# this ensures compatibility with the ValidMind sdk\n",
    "xgb.save(model, \"r_xgb_churn_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Simple Logistic Regression Model\n",
    "As a comparison, we train a simple logistic regression model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# now lets train a simple logistic regression model\n",
    "lg_reg_model <- glm(Exited ~ ., data = as.data.frame(df_train), family = \"binomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "We display a summary of the trained logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(lg_reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "coef(lg_reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data\n",
    "We make predictions on the test data and calculate the accuracy of the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "test_preds <- predict(lg_reg_model, newdata = as.data.frame(df_test), type = \"response\")\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "test_preds_binary <- ifelse(test_preds > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy <- sum(test_preds_binary == df_test[,\"Exited\"])/nrow(df_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Tests\n",
    "We calculate the confusion matrix, precision, recall, F1 score, and ROC AUC for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm <- confusionMatrix(as.factor(test_preds_binary), as.factor(df_test[,\"Exited\"]))\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[2, 1])\n",
    "recall <- cm$table[2, 2] / (cm$table[2, 2] + cm$table[1, 2])\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "cat(\"Precision:\", precision, \"\\n\")\n",
    "cat(\"Recall:\", recall, \"\\n\")\n",
    "cat(\"F1 Score:\", f1_score, \"\\n\")\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_obj <- roc(df_test[,\"Exited\"], test_preds)\n",
    "roc_auc <- auc(roc_obj)\n",
    "cat(\"ROC AUC:\", roc_auc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "We save the trained logistic regression model as an RDS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "saveRDS(lg_reg_model, \"r_log_reg_churn_model.rds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
