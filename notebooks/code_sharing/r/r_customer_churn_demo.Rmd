---
title: "Customer Churn Example (R)"
author: "ValidMind"
date: "2023-11-15"
output: html_document
---

# **Quickstart - Customer Churn Full Suite Model Documentation**

This interactive notebook will guide you through documenting a model using the ValidMind Developer framework. We will use sample datasets provided by the library and train a simple classification model.

For this simple demonstration, we will use the following bank customer churn dataset from Kaggle: <https://www.kaggle.com/code/kmalit/bank-customer-churn-prediction/data.>

We will train a sample model and demonstrate the following documentation functionalities:

\- Initializing the ValidMind Developer Framework

\- Using a sample datasets provided by the library to train a simple classification model

\- Running a test suite to quickly generate document about the data and model

## **Initializing the Python environment**

```{r setup, include=FALSE}
library(reticulate)

python_version <- "<path_to_python_version>"
use_python(python_version)

library(validmind)
library(caTools)
library(glmnet)
library(knitr)
library(dplyr)

knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## **Initializing the ValidMind Client Library**

Log in to the ValidMind platform with your registered email address, and navigate to the Documentation Projects page.

### **Creating a new Documentation Project**

*(Note: if a documentation project has already been created, you can skip this section and head directly "Finding Project API key and secret")*

Clicking on "Create a new project" allows to you to register a new documentation project for our demo model.

Select "Customer Churn model" from the Model drop-down, and "Initial Validation" as Type. Finally, click on "Create Project".

### **Finding the project API key and secret**

In the "Client Integration" page of the newly created project, you will find the initialization code that allows the client library to associate documentation and tests with the appropriate project. The initialization code configures the following arguments:

-   api_host: Location of the ValidMind API.

-   api_key: Account API key.

-   api_secret: Account Secret key.

-   project: The project identifier. The \`project\` argument is mandatory since it allows the library to associate all data collected with a specific account project.

The code snippet can be copied and pasted directly in the cell below to initialize the ValidMind Developer Framework when run:

```{r}
vm_r <- vm(
  api_key="<your_api_key_here>",
  api_secret="<your_api_secret_here>",
  model="<your_project_id_here>",
  python_version=python_version,
  api_host="https://api.dev.vm.validmind.ai/api/v1/tracking"
)
```

## **Load the Demo Dataset**

For the purpose of this demonstration, we will use a sample dataset provided by the ValidMind library.

```{r}
# Read the dataset
data <- read.csv('../datasets/bank_customer_churn.csv')
```

#### **Initialize a dataset object for ValidMind**

Before running the test plan, we must first initialize a ValidMind dataset object using the `init_dataset` function from the `vm` module. This function takes in arguments: `dataset` which is the dataset that we want to analyze; `target_column` which is used to identify the target variable; `class_labels` which is used to identify the labels used for classification model training.

```{r}
vm_dataset = vm_r$init_dataset(
    dataset=data,
    target_column="Exited",
    class_labels=list("0" = "Did not exit", "1" = "Exited")
)
```

## **Run the Data Validation Test Plan**

```{r}
tabular_suite_results <- vm_r$run_test_suite("tabular_dataset", dataset=vm_dataset)
```

```{r, results='hide'}
processed_results <- process_result(tabular_suite_results)
```

```{r, echo=FALSE, results='hide'}
all_widgets <- display_report(processed_results)
for (widget in all_widgets) {
  print(widget)
}
```

`r do.call(htmltools::tagList, all_widgets)`

## Modeling Results

We will need to preprocess the dataset and produce the training, test and validation splits first.

### **Preprocess the Raw Dataset**

```{r}
# Handle categorical variables using one-hot encoding and remove unnecessary columns
data <- data %>% select(-RowNumber, -CustomerId, -Surname)
geo_dummies <- model.matrix(~Geography - 1, data=data)
gender_dummies <- model.matrix(~Gender - 1, data=data)
data <- data %>% select(-Geography, -Gender)
data <- cbind(data, geo_dummies, gender_dummies)
```

```{r}
# Split the dataset into training and testing sets
set.seed(123) # Setting seed for reproducibility
split <- sample.split(data$Exited, SplitRatio = 0.7)
train_data <- subset(data, split == TRUE)
test_data <- subset(data, split == FALSE)
```

```{r}
model <- glm(Exited ~ ., family = binomial(link = 'logit'), data = train_data)
```

```{r}
model_path = save_model(model)
```

```{r}
vm_train_ds = vm_r$init_dataset(
  dataset=train_data,
  target_column="Exited"
)

vm_test_ds = vm_r$init_dataset(
  dataset=test_data,
  target_column="Exited"
)

vm_model = vm_r$init_r_model(
  model_path=model_path,
  train_ds=vm_train_ds,
  test_ds=vm_test_ds,
)
```

### **Run the Binary Classification Test Plan**

```{r}
model_validation_results = vm_r$run_test_suite("classifier_model_validation", model=vm_model,
                                               fail_fast = TRUE)
```

```{r, include=FALSE}
processed_results <- process_result(model_validation_results)
```

```{r, echo=FALSE, results='hide'}
all_widgets <- display_report(processed_results)
for (widget in all_widgets) {
  print(widget)
}
```

`r do.call(htmltools::tagList, all_widgets)`
