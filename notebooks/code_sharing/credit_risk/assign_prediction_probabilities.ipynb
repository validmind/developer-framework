{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign Prediction Values and Probabilities to ValidMind Datasets\n",
    "\n",
    "In this notebook, you will be guided through the process of assigning prediction values and prediction probabilities with the `assign_prediction()` using the inputs `prediction_values` and `prediction_probabilities`. These two type of predictions are common in classification and logistic resgression models, and you'll see how they can be implemented using a logistic regression model. Throughout this guide, you will learn to:\n",
    "\n",
    "- Assign prediction values and probabilities that have been computed outside ValidMind (VM).\n",
    "- Incorporate prediction values and probabilities from datasets that already have prediction columns.\n",
    "- Automate the assignment of prediction values and probabilities within VM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library\n",
    "\n",
    "The client library provides Python support for the ValidMind Developer Framework. To install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, [log in to ValidMind](https://docs.validmind.ai/guide/configuration/log-in-to-validmind.html).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/model-inventory/register-models-in-inventory.html))\n",
    "\n",
    "   For example, to register a model for use with this notebook, select:\n",
    "\n",
    "   - Documentation template: `Binary classification`\n",
    "   - Use case: `Marketing/Sales - Attrition/Churn Management`\n",
    "\n",
    "   You can fill in other options according to your preference.\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your code snippet\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the documentation template\n",
    "\n",
    "A template predefines sections for your model documentation and provides a general outline to follow, making the documentation process much easier.\n",
    "\n",
    "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.preview_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the sample dataset\n",
    "\n",
    "The sample dataset used here is provided by the ValidMind library. To be able to use it, you need to import the dataset and load it into a pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), a two-dimensional tabular data structure that makes use of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sample dataset from the library\n",
    "\n",
    "from validmind.datasets.credit_risk import lending_club\n",
    "\n",
    "df = lending_club.load_data(source=\"offline\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepocess the raw dataset\n",
    "\n",
    "Preprocessing performs a number of operations to get ready for the subsequent steps:\n",
    "\n",
    "- Preprocess the data: Splits the DataFrame (`df`) into multiple datasets (`train_df`, `validation_df`, and `test_df`) using `demo_dataset.preprocess` to simplify preprocessing.\n",
    "- Separate features and targets: Drops the target column to create feature sets (`x_train`, `x_val`) and target sets (`y_train`, `y_val`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_df = lending_club.preprocess(df)\n",
    "fe_df = lending_club.feature_engineering(preprocess_df)\n",
    "train_df, test_df = lending_club.split(fe_df, add_constant=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models for testing\n",
    "\n",
    "- Initialize a GLM Logistic Regression Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(lending_club.target_column, axis=1)\n",
    "y_train = train_df[lending_club.target_column]\n",
    "x_test = test_df.drop(lending_club.target_column, axis=1)\n",
    "y_test = test_df[lending_club.target_column]\n",
    "\n",
    "# Define the model\n",
    "model = sm.GLM(\n",
    "    y_train, \n",
    "    x_train, \n",
    "    family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "model = model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ValidMind objects\n",
    "\n",
    "### Initialize the ValidMind datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    input_id=\"train_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df, \n",
    "    input_id=\"test_dataset\", \n",
    "    target_column=lending_club.target_column\n",
    ")\n",
    "\n",
    "vm_model = vm.init_model(\n",
    "    model,\n",
    "    input_id=\"glm_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options to assign prediction values and probabilities to VM datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Assing predictions values and probabilities computed outside VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Compute probabilities from the model outside ValidMind\n",
    "train_probabilities = model.predict(x_train)\n",
    "test_probabilities = model.predict(x_test)\n",
    "\n",
    "# Compute binary predictions from the probabilities\n",
    "cut_off_threshold = 0.5\n",
    "train_binary_predictions = (train_probabilities > cut_off_threshold).astype(int)\n",
    "test_binary_predictions = (test_probabilities > cut_off_threshold).astype(int)\n",
    "\n",
    "# Compute scores from the probabilities \n",
    "train_scores = lending_club.compute_scores(train_probabilities)\n",
    "test_scores = lending_club.compute_scores(test_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(\n",
    "    model=vm_model,\n",
    "    prediction_values=train_binary_predictions,\n",
    "    prediction_probabilities = train_probabilities,\n",
    ")\n",
    "\n",
    "vm_test_ds.assign_predictions(\n",
    "    model=vm_model,\n",
    "    prediction_values=test_binary_predictions,\n",
    "    prediction_probabilities = test_probabilities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vm_test_ds)\n",
    "print(vm_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run some example tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test: \n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ROCCurve\",\n",
    "        inputs = {\n",
    "            \"dataset\": vm_test_ds,\n",
    "            \"model\": vm_model,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test: \n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.statsmodels.GINITable\",\n",
    "        input_grid = {\n",
    "            \"dataset\": [vm_train_ds, vm_test_ds],\n",
    "            \"model\": [vm_model],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test:\n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ClassifierPerformance\",\n",
    "        inputs = {\n",
    "            \"dataset\": vm_train_ds,\n",
    "            \"model\": vm_model,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assing prediction values and probabilities from datasets with existing prediction columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2 = train_df.copy()\n",
    "train_df2[\"glm_prediction_values\"] = train_binary_predictions\n",
    "train_df2[\"glm_prediction_probabilities\"] = train_probabilities\n",
    "train_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = test_df.copy()\n",
    "test_df2[\"glm_prediction_values\"] = test_binary_predictions\n",
    "test_df2[\"glm_prediction_probabilities\"] = test_probabilities\n",
    "test_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df2,\n",
    "    input_id=\"train_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df2,\n",
    "    input_id=\"test_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(\n",
    "    model=vm_model, \n",
    "    prediction_column=\"glm_prediction_values\",\n",
    "    probability_column=\"glm_prediction_probabilities\"\n",
    ")\n",
    "\n",
    "vm_test_ds.assign_predictions(\n",
    "    model=vm_model, \n",
    "    prediction_column=\"glm_prediction_values\",\n",
    "    probability_column=\"glm_prediction_probabilities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run some example tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test: \n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ROCCurve\",\n",
    "        inputs = {\n",
    "            \"dataset\": vm_test_ds,\n",
    "            \"model\": vm_model,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test: \n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.statsmodels.GINITable\",\n",
    "        input_grid = {\n",
    "            \"dataset\": [vm_train_ds, vm_test_ds],\n",
    "            \"model\": [vm_model],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test:\n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ClassifierPerformance\",\n",
    "        inputs = {\n",
    "            \"dataset\": vm_train_ds,\n",
    "            \"model\": vm_model,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Assign prediction values and probabilities computed automatically within VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    input_id=\"train_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df,\n",
    "    input_id=\"test_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(model=vm_model)\n",
    "vm_test_ds.assign_predictions(model=vm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vm_train_ds)\n",
    "print(vm_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run some example tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test: \n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ROCCurve\",\n",
    "        inputs = {\n",
    "            \"dataset\": vm_test_ds,\n",
    "            \"model\": vm_model,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test: \n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.statsmodels.GINITable\",\n",
    "        input_grid = {\n",
    "            \"datasets\": [vm_train_ds, vm_test_ds],\n",
    "            \"model\": [vm_model],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test = True\n",
    "if run_test:\n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ClassifierPerformance\",\n",
    "        inputs = {\n",
    "            \"dataset\": vm_train_ds,\n",
    "            \"model\": vm_model,\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
