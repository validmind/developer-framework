{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "da095bb3-4368-4154-9a6c-0911711790be",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## ValidMind Python Client Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-a91a41e8-53b4-4d72-ad25-b779163ecb2b",
    "deepnote_cell_height": 307.984375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The ValidMind Python client allows model developers and validators to automatically document different aspects of the model development lifecycle. \n",
    "\n",
    "For modelers, the client provides the following high level features:\n",
    "\n",
    "- Log qualitative data about the model's conceptual soundness\n",
    "- Log information about datasets and models\n",
    "- Log training and evaluation metrics about datasets and models\n",
    "- Run data quality checks\n",
    "- Run model evaluation tests\n",
    "\n",
    "For validators, the client also provides (TBD) the ability to effectively challenge the model's performance according to its objective, use case and specific project's requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cb3d95065c634710ba06e460fe4e143c",
    "deepnote_cell_height": 114.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Notebook Requirements\n",
    "\n",
    "- This notebook and the ValidMind client must be executed on an environment running Python >= 3.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-c54403d9-f83d-4e24-96e0-facd959a9513",
    "deepnote_cell_height": 122.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Installing the client library\n",
    "\n",
    "While we finish the process of making the library publicly accessible `pip`, it can be installed with the following command that will direct `pip` to the S3 bucket that contains the latest version of the client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "597ac6a094784a65a8141b342007a768",
    "deepnote_cell_height": 149.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 361,
    "execution_start": 1660150142847,
    "source_hash": "747bb2a4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API key and secret from environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-36cacfa2-342b-44e4-8799-9557b26a2c6d",
    "deepnote_cell_height": 324.578125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Creating a new project\n",
    "\n",
    "Before we test the client library with a dataset and a model, we need to create a new project on the ValidMind dashboard:\n",
    "\n",
    "- Navigate to the dashboard and click on the \"Create new Project\" button\n",
    "- Provide a name and description for the project\n",
    "- Select a model use case\n",
    "- For modeling objective, we only support automated documentation of `Binary Clasification` models at the moment\n",
    "\n",
    "After creating the project you will be provided with client library setup instructions. We have provided similar instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4ce25e6e546c4637a95d39867964c175",
    "deepnote_cell_height": 294.1875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Initializing the client library\n",
    "\n",
    "Every validation project in the ValidMind dashboard has an associated `project identifier`. In order to initialize the client, we need to provide the following arguments:\n",
    "\n",
    "- `project`: project identifier. The project identifier can be found in the dashboard URL when navigating to a project page, e.g. for `/projects/cl1jyvh2c000909lg1rk0a0zb` the project identifier is `cl1jyvh2c000909lg1rk0a0zb`\n",
    "- `api_host`: Location of the ValidMind API. This value is already set on this notebook.\n",
    "- `api_key`: Account API key. This can be found in the settings page in the ValidMind dashboard\n",
    "- `api_secret`: Account Secret key. Also found in the settings page in the ValidMind dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "4b874a48418b4a5dbb7f987c8b83be86",
    "deepnote_cell_height": 94,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1660150145739,
    "source_hash": "7c7b5350",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lookup your own project id\n",
    "# project='cla6walda00001wl6pdzagu9v'\n",
    "project='clar3ppjg000f1gmikrfmkld6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-b11f9d5b-e19b-4817-b1c1-c530dd579b93",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We can now initialize the client library with the `vm.init` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "bc1361cd166c4e59a6a461bf41420b62",
    "deepnote_cell_height": 203.1875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5638,
    "execution_start": 1660150150425,
    "source_hash": "61ae0397",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "    project=project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00015-75d09835-7bea-423b-b346-9fc3ed093451",
    "deepnote_cell_height": 202,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 220,
    "execution_start": 1660150159054,
    "source_hash": "fb29b98f"
   },
   "outputs": [],
   "source": [
    "# Necessary imports for training our demo models\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-9eb08086-0fc2-4818-b36f-8110b8a0fd99",
    "deepnote_cell_height": 382.78125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## ValidMind Client Library Functions\n",
    "\n",
    "As of version `0.8.x` of the client library, the following logging and testing functions are available:\n",
    "\n",
    "|Function|Description|\n",
    "|-|-|\n",
    "|`log_metadata`|Logs free-form metadata text for a given content ID in the model documentation|\n",
    "|`log_dataset`|Analyzes a dataset and logs its description, column definitions and summary statistics|\n",
    "|`run_dataset_tests`|Runs dataset quality tests on the input dataset|\n",
    "|`analyze_dataset`|Analyzes a dataset, computes summary statistics and runs data quality tests. This function combines `log_dataset` and `run_dataset_tests`|\n",
    "|`log_model`|Logs information about a model's framework, architecture, target objective and training parameters|\n",
    "|`log_training_metrics`|Extracts and logs training metrics from a pre-trained model|\n",
    "|`evaluate_model`|Extracts metadata and metrics from a train model instances and runs model evaluation tests according to the model objective, use case and specific validation requirements. This function combines `log_model`, `log_training_metrics` and an additional set of preconfigured model evaluation tests|\n",
    "\n",
    "\n",
    "\n",
    "In the example model training code in this notebook, we will demonstrate each of the documented client library functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-f814442c-d85e-4cc5-8a60-6b18610a0d26",
    "deepnote_cell_height": 283.28125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### `log_metadata`\n",
    "\n",
    "Logs free-form metadata text for a given content ID in the model documentation.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "- `content_id`: Content ID of the model documentation. This is a unique identifier generated by the ValidMind dashboard. See available `content_id`s in the model training section below\n",
    "- `text`: Free-form text to be logged. A text template can be specified in combination with `extra_json` (see below)\n",
    "- `extra_json`: (TBD support for this) JSON object containing variables to be substituted in the text template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-d87feadc-25b6-4869-98d3-bc8d4099ad13",
    "deepnote_cell_height": 541.875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### `analyze_dataset`\n",
    "\n",
    "Analyzes a dataset and logs its description, column definitions and summary statistics. The following information is extracted from the dataset:\n",
    "\n",
    "- Descriptive statistics for numerical and categorical columns\n",
    "- Histograms and value counts for summarizing distribution of values\n",
    "- Pearson correlation matrix for numerical columns\n",
    "- Corelation plots for top 15 correlated features\n",
    "\n",
    "Additionally, it will run a collection of data quality tests such as:\n",
    "\n",
    "- Class imbalance test on target column\n",
    "- Duplicate rows and duplicates based on primary key\n",
    "- High cardinality test on categorical columns\n",
    "- Missing values\n",
    "- Highly correlated column pairs\n",
    "- Skewness test\n",
    "- Zeros test (columns with too many zeros)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "- `dataset`: Input dataset. Only Pandas DataFrames are supported at the moment\n",
    "- `dataset_type`: Type of dataset, e.g. `training`, `test`, `validation`. Value needs to be set to `training` for now\n",
    "- `targets`: `vm.DatasetTargets` describing the label column and its values\n",
    "- `features`: Optional list of properties to specify for some features in the dataset\n",
    "\n",
    "Returns:\n",
    "\n",
    "- `results`: List of data quality test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-35c2c68b-5424-449a-a537-22acf5298873",
    "deepnote_cell_height": 573.671875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### `evaluate_model`\n",
    "\n",
    "Logs the following information about a model:\n",
    "\n",
    "- Model framework and architecture (e.g. XGBoost, Random Forest, Logistic Regression, etc.)\n",
    "- Model task details (e.g. binary classification, regression, etc.)\n",
    "- Model hyperparameters (e.g. number of trees, max depth, etc.)\n",
    "- Model performance metrics from training, validation and test dataset\n",
    "\n",
    "Additionally, this function runs model evaluation tests according to the model objective, use case and specific validation requirements. The following tests are available for binary classification models at the moment:\n",
    "\n",
    "- Accuracy score\n",
    "- Precision score\n",
    "- Recall score\n",
    "- F1 score\n",
    "- ROC AUC score\n",
    "- ROC AUC curve\n",
    "- Confusion matrix\n",
    "- Precision Recall curve\n",
    "- Permutation feature importance\n",
    "- SHAP global importance\n",
    "\n",
    "Arguments:\n",
    "\n",
    "- `model`: Trained model instance. Only Scikit-learn interface compatible models are supported at the moment\n",
    "- `train_set`: Training dataset tuple (x_train, y_train)\n",
    "- `val_set`: Validation dataset tuple (x_val, y_val)\n",
    "- `test_set`: Test dataset tuple (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-5db2af28-083e-4b02-b127-ee9a09b330d9",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Training an Example Model\n",
    "\n",
    "We'll now train an example model to demonstrate the ValidMind client library functions. The following demo datasets are available to use, and on this notebook we'll train a model for the Bank Customer Churn dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00024-9b9475e8-6d0a-4f2f-b4c7-725fab3c90f0",
    "deepnote_cell_height": 153,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2448,
    "execution_start": 1660150188409,
    "source_hash": "cc430a1a"
   },
   "outputs": [],
   "source": [
    "# Bank Customer Churn Dataset\n",
    "churn_dataset = pd.read_csv(\"https://vmai.s3.us-west-1.amazonaws.com/datasets/bank_customer_churn.csv\")\n",
    "\n",
    "# Health Insurance Cross-Sell Dataset\n",
    "insurance_dataset = pd.read_csv(\"https://vmai.s3.us-west-1.amazonaws.com/datasets/health_insurance_cross_sell.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_dataset2 = pd.read_csv(\"https://gist.githubusercontent.com/mehdi0501/5b9e64b51ed3bbddbe8f018fc7caf626/raw/ee9b21e5f5308299eb5f4d9dd251bc1b9c5ecc85/churn_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        8000 non-null   int64  \n",
      " 1   CustomerId       8000 non-null   int64  \n",
      " 2   Surname          8000 non-null   object \n",
      " 3   CreditScore      8000 non-null   int64  \n",
      " 4   Geography        8000 non-null   object \n",
      " 5   Gender           8000 non-null   object \n",
      " 6   Age              8000 non-null   int64  \n",
      " 7   Tenure           8000 non-null   int64  \n",
      " 8   Balance          8000 non-null   float64\n",
      " 9   NumOfProducts    8000 non-null   int64  \n",
      " 10  HasCrCard        8000 non-null   int64  \n",
      " 11  IsActiveMember   8000 non-null   int64  \n",
      " 12  EstimatedSalary  8000 non-null   float64\n",
      " 13  Exited           8000 non-null   int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 875.1+ KB\n"
     ]
    }
   ],
   "source": [
    "churn_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "081db767e00a43bfa4028d2071f58d60",
    "deepnote_cell_height": 376.78125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### log_metadata\n",
    "\n",
    "Before we start logging information about our dataset, we'd want to send metadata to ValidMind about the model's conceptual soundness, for example. Model developers have the option to directly populate parts of the dashboard documentation using special `content_id`s. The following is the list of `content_id`s supported at the moment:\n",
    "\n",
    "|Content ID|Populates Section|\n",
    "|-|-|\n",
    "|model_overview|Conceptual Soundness -> Model Overview|\n",
    "|model_selection|Conceptual Soundness -> Model Selection|\n",
    "|business_case|Conceptual Soundness -> Intended Use and Business Use Case|\n",
    "|feature_selection|Data Preparation -> Feature Selection and Engineering|\n",
    "|governance_plan|Monitoring and Governance -> Governance Plan|\n",
    "|monitoring_implementation|Monitoring and Governance -> Monitoring Implementation|\n",
    "|monitoring_plan|Monitoring and Governance -> Monitoring Plan|\n",
    "\n",
    "In the following `log_metadata` example, we will populate the `Model Overview` section in the dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "a0ef0c732b854f71860615155e2d1aef",
    "deepnote_cell_height": 356.875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 791,
    "execution_start": 1660150191341,
    "source_hash": "218baf64",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_overview = \"\"\"\n",
    "We aim to accomplish the following for this study:\n",
    "\n",
    "- Identify and visualize which factors contribute to customer churn\n",
    "- Build a prediction model that will perform the following:\n",
    "  - Classify if a customer is going to churn or not\n",
    "  - Preferably and based on model performance, choose a model that will attach a probability\n",
    "  to the churn to make it easier for customer service to target low hanging fruits in their\n",
    "  efforts to prevent churn\n",
    "\"\"\"\n",
    "\n",
    "vm.log_metadata(content_id=\"model_overview\", text=model_overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "acb65079018d4dff90114aa7321fe3cb",
    "deepnote_cell_height": 74.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We can now go to `Project Overview -> Documentation -> Model Overview` and verify this content has been populated on the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-bb41f402-6089-46c0-bb08-e7b93288ccb7",
    "deepnote_cell_height": 145.6875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### `analyze_dataset`\n",
    "\n",
    "After loading the dataset, we can log metadata and summary statistics, and run data quality checks for it using `analyze_dataset`. Note that the `analyze_dataset` function expects a `targets` definition. Additional information about columns can be provided with the `features` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00026-908e24f9-be53-4645-a78f-a42c812aede1",
    "deepnote_cell_height": 490,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7034,
    "execution_start": 1660150194903,
    "source_hash": "3fb0224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing dataset...\n",
      "Pandas dataset detected.\n",
      "Inferring dataset types...\n",
      "Preparing in-memory dataset copy...\n",
      "Calculating field statistics...\n",
      "Calculating feature correlations...\n",
      "Generating correlation plots...\n",
      "Successfully logged dataset metadata and statistics.\n",
      "Running data quality tests...\n",
      "Running data quality tests for \"training\" dataset...\n",
      "\n",
      "Preparing dataset for tests...\n",
      "Preparing in-memory dataset copy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 22.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test suite has completed.\n",
      "Sending results to ValidMind...\n",
      "Successfully logged test results for test: class_imbalance\n",
      "Successfully logged test results for test: duplicates\n",
      "Successfully logged test results for test: cardinality\n",
      "Successfully logged test results for test: missing\n",
      "Successfully logged test results for test: skewness\n",
      "Successfully logged test results for test: zeros\n",
      "\n",
      "Summary of results:\n",
      "\n",
      "Test             Passed      # Passed    # Errors    % Passed\n",
      "---------------  --------  ----------  ----------  ----------\n",
      "class_imbalance  True               1           0         100\n",
      "duplicates       True               2           0         100\n",
      "cardinality      False              6           1     85.7143\n",
      "missing          True              14           0         100\n",
      "skewness         False              6           1     85.7143\n",
      "zeros            False              0           2           0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn_targets = vm.DatasetTargets(\n",
    "    target_column=\"Exited\",\n",
    "    class_labels={\n",
    "        \"0\": \"Did not exit\",\n",
    "        \"1\": \"Exited\",\n",
    "    }\n",
    ")\n",
    "\n",
    "churn_features = [\n",
    "    {\n",
    "        \"id\": \"RowNumber\",\n",
    "        \"type_options\": {\n",
    "            \"primary_key\": True,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "analyze_results = vm.analyze_dataset(\n",
    "    dataset=churn_dataset,\n",
    "    dataset_type=\"training\",\n",
    "    targets=churn_targets,\n",
    "    features=churn_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-f6fc5e04-8f84-4529-a72f-c614ba81a97e",
    "deepnote_cell_height": 111.1875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "After running `analyze_dataset`, we can open the ValidMind dashboard on the following section to verify that the dataset and its data quality checks have been documented correctly:\n",
    "\n",
    "`Dashboard -> Project Overview -> Documentation -> Data Description`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-1a9ef24a-4291-4f87-9d2f-1e138e725e0b",
    "deepnote_cell_height": 122.796875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Preparing the training dataset\n",
    "\n",
    "We are now going to preprocess and prepare our training, validation and test datasets so we can train an example model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00031-7a9fada3-e218-47d7-9fb4-64ce86f7161d",
    "deepnote_cell_height": 292,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1660150206418,
    "source_hash": "dbf65f41"
   },
   "outputs": [],
   "source": [
    "def preprocess_churn_dataset(df):\n",
    "    # Drop columns with no correlation to target\n",
    "    df.drop([\"RowNumber\", \"CustomerId\", \"Surname\", \"CreditScore\"], axis=1, inplace=True)\n",
    "\n",
    "    # Encode binary features\n",
    "    genders = {\"Male\": 0, \"Female\": 1}\n",
    "    df.replace({\"Gender\": genders}, inplace=True)\n",
    "\n",
    "    # Encode categorical features\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"Geography\"], prefix=\"Geography\")], axis=1)\n",
    "    df.drop(\"Geography\", axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00032-06140a9c-54e6-41a6-9287-55b8d391b5bf",
    "deepnote_cell_height": 76,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1660150208846,
    "source_hash": "2f817a8c"
   },
   "outputs": [],
   "source": [
    "preprocessed_churn = preprocess_churn_dataset(churn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-55dc2dd1-1209-4b1f-809a-322f5a62fa6f",
    "deepnote_cell_height": 364,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1660150210664,
    "source_hash": "ec9ea158"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split_dataset(df):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.20)\n",
    "\n",
    "    # This guarantees a 60/20/20 split\n",
    "    train_ds, val_ds = train_test_split(train_df, test_size=0.25)\n",
    "\n",
    "    # For training\n",
    "    x_train = train_ds.drop(\"Exited\", axis=1)\n",
    "    y_train = train_ds.loc[:, \"Exited\"].astype(int)\n",
    "    x_val = val_ds.drop(\"Exited\", axis=1)\n",
    "    y_val = val_ds.loc[:, \"Exited\"].astype(int)\n",
    "\n",
    "    # For testing\n",
    "    x_test = test_df.drop(\"Exited\", axis=1)\n",
    "    y_test = test_df.loc[:, \"Exited\"].astype(int)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00034-d60be9d2-ff35-42e9-babf-9a3a0e854633",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1660150212945,
    "source_hash": "279b84e3"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = train_val_test_split_dataset(preprocessed_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-6c629183-9e67-4fec-afd2-1fa03bb7bdd5",
    "deepnote_cell_height": 310,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1660150214834,
    "source_hash": "dc0d58f8"
   },
   "outputs": [],
   "source": [
    "def train_churn_dataset(x_train, y_train, x_val, y_val):\n",
    "    xgb_model = xgb.XGBClassifier(early_stopping_rounds=10)\n",
    "\n",
    "    xgb_model.set_params(\n",
    "        eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
    "    )    \n",
    "\n",
    "    xgb_model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-b232a11d-d9d8-479e-b3bd-dfb486eeee2e",
    "deepnote_cell_height": 76,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 679,
    "execution_start": 1660150217238,
    "source_hash": "cf70757c"
   },
   "outputs": [],
   "source": [
    "xgb_model = train_churn_dataset(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00037-2a657d33-e3ac-49f9-b99b-08b265bc83ad",
    "deepnote_cell_height": 166,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1660150218595,
    "source_hash": "70065d56"
   },
   "outputs": [],
   "source": [
    "def model_accuracy(model, x, y):\n",
    "    y_pred = model.predict_proba(x)[:, -1]\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00038-6ed7400b-0c9e-459e-a0a8-a7cc26efd358",
    "deepnote_cell_height": 107,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 576,
    "execution_start": 1660150220494,
    "source_hash": "24509ff3"
   },
   "outputs": [],
   "source": [
    "model_accuracy(xgb_model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-0009065f-7dcd-476d-8b3b-de7cc1674cb4",
    "deepnote_cell_height": 100.890625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### `evaluate_model`\n",
    "\n",
    "Finally, after training our model, we can log its model parameters, collect performance metrics and run model evaluation tests on it using `evaluate_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00045-5290db02-488f-49d1-83bc-94b60b8a70e3",
    "deepnote_cell_height": 1835.875,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     270,
     286,
     286,
     286
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6070,
    "execution_start": 1660150229353,
    "source_hash": "5ce751f3"
   },
   "outputs": [],
   "source": [
    "eval_results = vm.evaluate_model(\n",
    "    xgb_model,\n",
    "    train_set=(x_train, y_train),\n",
    "    val_set=(x_val, y_val),\n",
    "    test_set=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00046-1f975bbb-952b-40af-8a3a-360336acd7bc",
    "deepnote_cell_height": 172.984375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "After running `evaluate_model`, we can open the ValidMind dashboard on the following sections to verify that the model evaluation test results have been logged correctly:\n",
    "\n",
    "- `Dashboard -> Project Overview -> Documentation -> Model Development -> Model Evaluation`\n",
    "- `Dashboard -> Project Overview -> Documentation -> Model Development -> Model Explainability and Interpretability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "71b70118-96c8-463b-94e5-733fca330035",
  "kernelspec": {
   "display_name": "Python 3.8.6 ('validmind-Jp3s24zK-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5507f2e99c1cac96073e07e686bb64d511c5f1c7216ba7fc4306f43af6557f44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
