{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarization of Financial Data Using Hugging Face NLP models\n",
        "\n",
        "This notebook shows model developers how to document a natural language processing (NLP) model using the ValidMind Developer Framework. The use case is a summarization of financial news based on a dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. It shows you how to set up the ValidMind Developer Framework, initialize the client library, and load the dataset, followed by running the model validation tests provided by the framework to quickly generate documentation about the data and model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ValidMind at a glance\n",
        "\n",
        "ValidMind's platform enables organizations to identify, document, and manage model risks for all types of models, including AI/ML models, LLMs, and statistical models. As a model developer, you use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on documentation projects. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
        "\n",
        "If this is your first time trying out ValidMind, we recommend going through the following resources first:\n",
        "\n",
        "- [Get started](https://docs.validmind.ai/guide/get-started.html) — The basics, including key concepts, and how our products work\n",
        "- [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/guide/get-started-developer-framework.html) —  The path for developers, more code samples, and our developer reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before you begin\n",
        "\n",
        "::: {.callout-tip}\n",
        "### New to ValidMind? \n",
        "For access to all features available in this notebook, create a free ValidMind account. \n",
        "\n",
        "Signing up is FREE — [**Sign up now**](https://app.prod.validmind.ai)\n",
        ":::\n",
        "\n",
        "\n",
        "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install the client library\n",
        "\n",
        "The client library provides Python support for the ValidMind Developer Framework. To install it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q validmind"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the client library\n",
        "\n",
        "Every documentation project in the Platform UI comes with a _code snippet_ that lets the client library associate your documentation and tests with the right project on the Platform UI when you run this notebook.\n",
        "\n",
        "Get your code snippet by creating a documentation project:\n",
        "\n",
        "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
        "\n",
        "2. Go to Go to **Documentation Projects** and click **Create new project**.\n",
        "\n",
        "3. Select **`[Demo] Hugging Face - Text Summarization`** and **`Initial Validation`** for the model name and type, give the project a unique  name to make it yours, and then click **Create project**.\n",
        "\n",
        "4. Go to **Documentation Projects** > **YOUR_UNIQUE_PROJECT_NAME** > **Getting Started** and click **Copy snippet to clipboard**.\n",
        "\n",
        "Next, replace this placeholder with your own code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Replace the code below with the code snippet from your project ##\n",
        "\n",
        "\n",
        "import validmind as vm\n",
        "\n",
        "vm.init(\n",
        "  api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
        "  api_key = \"...\",\n",
        "  api_secret = \"...\",\n",
        "  project = \"...\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preview the documentation template\n",
        "\n",
        "A template predefines sections for your documentation project and provides a general outline to follow, making the documentation process much easier.\n",
        "\n",
        "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.preview_template()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions\n",
        "\n",
        "Let's define the following functions to help visualize datasets with long text fields:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from tabulate import tabulate\n",
        "\n",
        "def _format_cell_text(text, width=50):\n",
        "    \"\"\"Private function to format a cell's text.\"\"\"\n",
        "    return '\\n'.join([textwrap.fill(line, width=width) for line in text.split('\\n')])\n",
        "\n",
        "def _format_dataframe_for_tabulate(df):\n",
        "    \"\"\"Private function to format the entire DataFrame for tabulation.\"\"\"\n",
        "    df_out = df.copy()\n",
        "\n",
        "    # Format all string columns\n",
        "    for column in df_out.columns:\n",
        "        if df_out[column].dtype == object:  # Check if column is of type object (likely strings)\n",
        "            df_out[column] = df_out[column].apply(_format_cell_text)\n",
        "    return df_out\n",
        "\n",
        "def _dataframe_to_html_table(df):\n",
        "    \"\"\"Private function to convert a DataFrame to an HTML table.\"\"\"\n",
        "    headers = df.columns.tolist()\n",
        "    table_data = df.values.tolist()\n",
        "    return tabulate(table_data, headers=headers, tablefmt=\"html\")\n",
        "\n",
        "def display_formatted_dataframe(df, num_rows=None):\n",
        "    \"\"\"Primary function to format and display a DataFrame.\"\"\"\n",
        "    if num_rows is not None:\n",
        "        df = df.head(num_rows)\n",
        "    formatted_df = _format_dataframe_for_tabulate(df)\n",
        "    html_table = _dataframe_to_html_table(formatted_df)\n",
        "    display(HTML(html_table))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the dataset\n",
        "\n",
        "The CNN Dailymail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail (https://huggingface.co/datasets/cnn_dailymail). The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "cnn_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
        "train_df = cnn_dataset.data['train'].to_pandas()\n",
        "val_df = cnn_dataset.data['validation'].to_pandas()\n",
        "test_df = cnn_dataset.data['test'].to_pandas()\n",
        "train_df = train_df[['article','highlights']]\n",
        "train_df = train_df.head(20)\n",
        "\n",
        "display_formatted_dataframe(train_df, num_rows=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = train_df.head(100)\n",
        "# Load a test dataset with 100 rows only\n",
        "vm_ds = vm.init_dataset(\n",
        "    dataset=df,\n",
        "    text_column=\"article\",\n",
        "    target_column=\"highlights\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NLP data quality tests\n",
        "\n",
        "Before we proceed with the analysis, it's crucial to ensure the quality of our NLP data. We can run the `data_preparation` section of the template to validate the data's integrity and suitability:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_data_test_plan = vm.run_documentation_tests(\n",
        "    section=\"data_preparation\",\n",
        "    inputs = {\"dataset\":vm_ds}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "summarizer_model = pipeline(\n",
        "    task=\"summarization\",\n",
        "    model=model,\n",
        "    tokenizer = tokenizer,\n",
        "    min_length=0,\n",
        "    max_length=60,\n",
        "    truncation=True,\n",
        "    model_kwargs={\"cache_dir\": '/Documents/Huggin_Face/'},\n",
        ")  # Note: We specify cache_dir to use predownloaded models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = df.head(10)\n",
        "\n",
        "vm_test_ds = vm.init_dataset(\n",
        "    dataset=train_df,\n",
        "    text_column=\"article\",\n",
        "    target_column=\"highlights\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_model = vm.init_model(\n",
        "    summarizer_model,\n",
        "    test_ds=vm_test_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run model validation tests\n",
        "\n",
        "It's possible to run a subset of tests on the documentation template by passing a `section` parameter to `run_documentation_tests()`. Let's run only the tests that evaluate the model's overall performance, including summarization metrics, by selecting the `model_development` section of the template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config={\n",
        "    \"rouge_metric\": {\n",
        "        \"rouge_metrics\": [\"rouge-1\",\"rouge-2\", \"rouge-l\"],\n",
        "    },\n",
        "}\n",
        "summarization_results = vm.run_documentation_tests(\n",
        "    section=\"model_development\",\n",
        "    inputs = {\"model\":vm_model},\n",
        "    config=config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "You can look at the results of this test suite right in the notebook where you ran the code, as you would expect. But there is a better way: view the prompt validation test results as part of your model documentation right in the ValidMind Platform UI: \n",
        "\n",
        "1. Log back into the [Platform UI](https://app.prod.validmind.ai) \n",
        "\n",
        "2. Go to **Documentation Projects** > **YOUR_DOCUMENTATION_PROJECT** > **Documentation**.\n",
        "\n",
        "3. Expand **2. Data Preparation** or **3. Model Development** to review all test results.\n",
        "\n",
        "What you can see now is a more easily consumable version of the prompt validation testing you just performed, along with other parts of your documentation project that still need to be completed. \n",
        "\n",
        "If you want to learn more about where you are in the model documentation process, take a look at [How do I use the framework?](https://docs.validmind.ai/guide/get-started-developer-framework.html#how-do-i-use-the-framework).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Developer Framework",
      "language": "python",
      "name": "dev-framework"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
