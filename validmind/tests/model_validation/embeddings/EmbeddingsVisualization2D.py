# Copyright Â© 2023-2024 ValidMind Inc. All rights reserved.
# See the LICENSE file in the root of this repository for details.
# SPDX-License-Identifier: AGPL-3.0 AND ValidMind Commercial

import plotly.express as px
from sklearn.manifold import TSNE

from validmind.vm_models import Figure, Metric


class EmbeddingsVisualization2D(Metric):
    """
    Visualizes 2D representation of text embeddings generated by a model using t-SNE technique.

    **1. Purpose:** The objective of this metric is to provide a visual 2D representation of the embeddings created by
    a text embedding machine learning model. By doing so, it aids in analyzing the embedding space created by the model
    and helps in understanding how the learned embeddings are distributed and how they relate to each other.

    **2. Test Mechanism:** This metric uses the t-Distributed Stochastic Neighbor Embedding (t-SNE) technique, which is
    a tool for visualizing high-dimensional data by reducing the dimensionality to 2. The perplexity parameter for
    t-SNE is set to the value provided by the user. If the input perplexity value is greater than the number of
    samples, the perplexity is adjusted to be one less than the number of samples. Following the reduction of
    dimensionality, a scatter plot is produced depicting each embedding as a data point in the visualized 2D plane.

    **3. Signs of High Risk:**

    - If the embeddings are highly concentrated in a specific region of the plane, it might indicate that the model is
    not learning diverse representations of the text.
    - Wide gaps or partitions in the visualization could suggest that the model is over-segmenting in the embedding
    space and may lead to poor generalization.

    **4. Strengths:**

    - Offers a powerful visual tool that can assist in understanding and interpreting high-dimensional embeddings,
    which could otherwise be difficult to visualize.
    - It is model-agnostic and can be used with any machine learning model that produces text embeddings.
    - t-SNE visualization helps in focusing on local structures and preserves the proximity of points that are close
    together in the original high-dimensional space.

    **5. Limitations:**

    - The reduction of high-dimensional data to 2D can result in loss of some information, which may lead to
    misinterpretation.
    - Due to its stochastic nature, t-SNE can produce different results when run multiple times with the same
    parameters, leading to potential inconsistency in interpretation.
    - It is designed for visual exploration and not for downstream tasks; that is, the 2D embeddings generated should
    not be directly used for further training or analysis.
    """

    name = "2D Visualization of Text Embeddings"
    required_inputs = ["model", "dataset"]
    default_params = {
        "cluster_column": None,
        "perplexity": 30,
    }
    metadata = {
        "task_types": ["feature_extraction"],
        "tags": ["llm", "text_data", "text_embeddings", "visualization"],
    }

    def run(self):
        cluster_column = self.params.get("cluster_column")

        if cluster_column is None:
            raise ValueError(
                "The `cluster_column` parameter must be provided to the EmbeddingsVisualization2D test."
            )

        # use TSNE to reduce dimensionality of embeddings
        num_samples = len(self.inputs.dataset.y_pred(self.inputs.model))

        if self.params["perplexity"] >= num_samples:
            perplexity = num_samples - 1
        else:
            perplexity = self.params["perplexity"]

        reduced_embeddings = TSNE(
            n_components=2,
            perplexity=perplexity,
        ).fit_transform(self.inputs.model.y_test_predict.values)

        # create a scatter plot from the reduced embeddings
        fig = px.scatter(
            x=reduced_embeddings[:, 0],
            y=reduced_embeddings[:, 1],
            color=self.inputs.dataset.df[cluster_column],
            title="2D Visualization of Text Embeddings",
        )
        fig.update_layout(width=500, height=500)

        return self.cache_results(
            figures=[
                Figure(
                    for_object=self,
                    key=self.key,
                    figure=fig,
                )
            ],
        )
